{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "papermill": {
      "duration": 297.094983,
      "end_time": "2020-10-19T05:28:36.576660",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2020-10-19T05:23:39.481677",
      "version": "2.1.0"
    },
    "colab": {
      "name": "Deep N-Gram Models",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SauravMaheshkar/trax/blob/SauravMaheshkar-example-1/examples/Deep_N_Gram_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAAzPCP8n05S"
      },
      "source": [
        "#@title\n",
        "# Copyright 2020 Google LLC.\n",
        "\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CcV2B-3LnvBk"
      },
      "source": [
        "Author - [@SauravMaheshkar](https://github.com/SauravMaheshkar)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.024472,
          "end_time": "2020-10-19T05:23:45.163806",
          "exception": false,
          "start_time": "2020-10-19T05:23:45.139334",
          "status": "completed"
        },
        "tags": [],
        "id": "uEg7rw6fnr0q"
      },
      "source": [
        "# Downloading the Trax Package"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.024546,
          "end_time": "2020-10-19T05:23:45.211638",
          "exception": false,
          "start_time": "2020-10-19T05:23:45.187092",
          "status": "completed"
        },
        "tags": [],
        "id": "7iVotT-qnr0q"
      },
      "source": [
        "[Trax](https://trax-ml.readthedocs.io/en/latest/) is an end-to-end library for deep learning that focuses on clear code and speed. It is actively used and maintained in the [Google Brain team](https://research.google/teams/brain/). This notebook ([run it in colab](https://colab.research.google.com/github/google/trax/blob/master/trax/intro.ipynb)) shows how to use Trax and where you can find more information."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_kg_hide-input": false,
        "_kg_hide-output": true,
        "execution": {
          "iopub.execute_input": "2020-10-19T05:23:45.265606Z",
          "iopub.status.busy": "2020-10-19T05:23:45.264326Z",
          "iopub.status.idle": "2020-10-19T05:24:40.876515Z",
          "shell.execute_reply": "2020-10-19T05:24:40.877287Z"
        },
        "papermill": {
          "duration": 55.642763,
          "end_time": "2020-10-19T05:24:40.877583",
          "exception": false,
          "start_time": "2020-10-19T05:23:45.234820",
          "status": "completed"
        },
        "tags": [],
        "id": "LTV7nHkWnr0q"
      },
      "source": [
        "%%capture\n",
        "!pip install trax"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.121469,
          "end_time": "2020-10-19T05:24:41.120599",
          "exception": false,
          "start_time": "2020-10-19T05:24:40.999130",
          "status": "completed"
        },
        "tags": [],
        "id": "s4e-X6Ranr0s"
      },
      "source": [
        "# Importing Packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.117117,
          "end_time": "2020-10-19T05:24:41.355694",
          "exception": false,
          "start_time": "2020-10-19T05:24:41.238577",
          "status": "completed"
        },
        "tags": [],
        "id": "zaoHVZj0nr0s"
      },
      "source": [
        "In this notebook we will use the following packages:\n",
        "\n",
        "* [**Pandas**](https://pandas.pydata.org/) is a fast, powerful, flexible and easy to use open-source data analysis and manipulation tool, built on top of the Python programming language. It offers a fast and efficient DataFrame object for data manipulation with integrated indexing.\n",
        "* [**os**](https://docs.python.org/3/library/os.html) module provides a portable way of using operating system dependent functionality.\n",
        "* [**trax**](https://trax-ml.readthedocs.io/en/latest/trax.html) is an end-to-end library for deep learning that focuses on clear code and speed.\n",
        "* [**random**](https://docs.python.org/3/library/random.html) module implements pseudo-random number generators for various distributions.\n",
        "* [**itertools**](https://docs.python.org/3/library/itertools.html) module implements a number of iterator building blocks inspired by constructs from APL, Haskell, and SML. Each has been recast in a form suitable for Python."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2020-10-19T05:24:41.598509Z",
          "iopub.status.busy": "2020-10-19T05:24:41.597670Z",
          "iopub.status.idle": "2020-10-19T05:24:54.656423Z",
          "shell.execute_reply": "2020-10-19T05:24:54.655287Z"
        },
        "papermill": {
          "duration": 13.181434,
          "end_time": "2020-10-19T05:24:54.656623",
          "exception": false,
          "start_time": "2020-10-19T05:24:41.475189",
          "status": "completed"
        },
        "tags": [],
        "id": "h8vjYA-8nr0s"
      },
      "source": [
        "import pandas as pd \n",
        "import os\n",
        "import trax\n",
        "import trax.fastmath.numpy as np\n",
        "import random as rnd\n",
        "from trax import fastmath\n",
        "from trax import layers as tl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.118759,
          "end_time": "2020-10-19T05:24:54.899617",
          "exception": false,
          "start_time": "2020-10-19T05:24:54.780858",
          "status": "completed"
        },
        "tags": [],
        "id": "ZZaUGa2Lnr0s"
      },
      "source": [
        "# Loading the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.122704,
          "end_time": "2020-10-19T05:24:55.144895",
          "exception": false,
          "start_time": "2020-10-19T05:24:55.022191",
          "status": "completed"
        },
        "tags": [],
        "id": "WbwaTxIFnr0s"
      },
      "source": [
        "For this project, I've used the [gothic-literature](https://www.kaggle.com/charlesaverill/gothic-literature), [shakespeare-plays](https://www.kaggle.com/kingburrito666/shakespeare-plays) and [shakespeareonline](https://www.kaggle.com/kewagbln/shakespeareonline) datasets from the Kaggle library. \n",
        "\n",
        "We perform the following steps for loading in the data:\n",
        "\n",
        "* Iterate over all the directories in the `/kaggle/input/` directory\n",
        "* Filter out `.txt` files\n",
        "* Make a `lines` list containing the individual lines from all the datasets combined"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-19T05:24:55.385118Z",
          "iopub.status.busy": "2020-10-19T05:24:55.384122Z",
          "iopub.status.idle": "2020-10-19T05:24:55.716407Z",
          "shell.execute_reply": "2020-10-19T05:24:55.715479Z"
        },
        "papermill": {
          "duration": 0.456359,
          "end_time": "2020-10-19T05:24:55.716572",
          "exception": false,
          "start_time": "2020-10-19T05:24:55.260213",
          "status": "completed"
        },
        "tags": [],
        "id": "a7mudKI5nr0s"
      },
      "source": [
        "directories = os.listdir('/kaggle/input/')\n",
        "lines = []\n",
        "for directory in directories:\n",
        "    for filename in os.listdir(os.path.join('/kaggle/input',directory)):\n",
        "        if filename.endswith(\".txt\"):\n",
        "            with open(os.path.join(os.path.join('/kaggle/input',directory), filename)) as files:\n",
        "                for line in files: \n",
        "                    processed_line = line.strip()\n",
        "                    if processed_line:\n",
        "                        lines.append(processed_line)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.113664,
          "end_time": "2020-10-19T05:24:55.951966",
          "exception": false,
          "start_time": "2020-10-19T05:24:55.838302",
          "status": "completed"
        },
        "tags": [],
        "id": "EPifypFdnr0s"
      },
      "source": [
        "## Pre-Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.119888,
          "end_time": "2020-10-19T05:24:56.194726",
          "exception": false,
          "start_time": "2020-10-19T05:24:56.074838",
          "status": "completed"
        },
        "tags": [],
        "id": "eU58tWP3nr0s"
      },
      "source": [
        "### Converting to Lowercase\n",
        "\n",
        "Converting all the characters in the `lines` list to **lowercase**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-19T05:24:56.496346Z",
          "iopub.status.busy": "2020-10-19T05:24:56.470575Z",
          "iopub.status.idle": "2020-10-19T05:24:56.569027Z",
          "shell.execute_reply": "2020-10-19T05:24:56.569637Z"
        },
        "papermill": {
          "duration": 0.253923,
          "end_time": "2020-10-19T05:24:56.569875",
          "exception": false,
          "start_time": "2020-10-19T05:24:56.315952",
          "status": "completed"
        },
        "tags": [],
        "id": "QAxU3uzunr0s"
      },
      "source": [
        "for i, line in enumerate(lines):\n",
        "    lines[i] = line.lower()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.11122,
          "end_time": "2020-10-19T05:24:56.795120",
          "exception": false,
          "start_time": "2020-10-19T05:24:56.683900",
          "status": "completed"
        },
        "tags": [],
        "id": "voNUJBrRnr0s"
      },
      "source": [
        "### Converting into Tensors\n",
        "\n",
        "Creating a function to convert each line into a tensor by converting each character into it's ASCII value. And adding a optional `EOS`(**End of statement**) character."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-19T05:24:57.032580Z",
          "iopub.status.busy": "2020-10-19T05:24:57.029673Z",
          "iopub.status.idle": "2020-10-19T05:24:57.037237Z",
          "shell.execute_reply": "2020-10-19T05:24:57.036444Z"
        },
        "papermill": {
          "duration": 0.131432,
          "end_time": "2020-10-19T05:24:57.037392",
          "exception": false,
          "start_time": "2020-10-19T05:24:56.905960",
          "status": "completed"
        },
        "tags": [],
        "id": "J0F2sUJfnr0s"
      },
      "source": [
        "def line_to_tensor(line, EOS_int=1):\n",
        "    \n",
        "    tensor = []\n",
        "    for c in line:\n",
        "        c_int = ord(c)\n",
        "        tensor.append(c_int)\n",
        "    \n",
        "    tensor.append(EOS_int)\n",
        "\n",
        "    return tensor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.109763,
          "end_time": "2020-10-19T05:24:57.259043",
          "exception": false,
          "start_time": "2020-10-19T05:24:57.149280",
          "status": "completed"
        },
        "tags": [],
        "id": "zYT5__Danr0s"
      },
      "source": [
        "### Creating a Batch Generator\n",
        "\n",
        "Here, we create a `batch_generator()` function to yield a batch and mask generator. We perform the following steps:\n",
        "\n",
        "* Shuffle the lines if not shuffled\n",
        "* Convert the lines into a Tensor\n",
        "* Pad the lines if it's less than the maximum length\n",
        "* Generate a mask "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-19T05:24:57.491159Z",
          "iopub.status.busy": "2020-10-19T05:24:57.490293Z",
          "iopub.status.idle": "2020-10-19T05:24:57.503719Z",
          "shell.execute_reply": "2020-10-19T05:24:57.502899Z"
        },
        "papermill": {
          "duration": 0.134497,
          "end_time": "2020-10-19T05:24:57.503870",
          "exception": false,
          "start_time": "2020-10-19T05:24:57.369373",
          "status": "completed"
        },
        "tags": [],
        "id": "V-D_5L_snr0s"
      },
      "source": [
        "def data_generator(batch_size, max_length, data_lines, line_to_tensor=line_to_tensor, shuffle=True):\n",
        "    \n",
        "    index = 0                         \n",
        "    cur_batch = []                    \n",
        "    num_lines = len(data_lines)       \n",
        "    lines_index = [*range(num_lines)] \n",
        "\n",
        "    if shuffle:\n",
        "        rnd.shuffle(lines_index)\n",
        "    \n",
        "    while True:\n",
        "        \n",
        "        if index >= num_lines:\n",
        "            index = 0\n",
        "            if shuffle:\n",
        "                rnd.shuffle(lines_index)\n",
        "            \n",
        "        line = data_lines[lines_index[index]] \n",
        "        \n",
        "        if len(line) < max_length:\n",
        "            cur_batch.append(line)\n",
        "            \n",
        "        index += 1\n",
        "        \n",
        "        if len(cur_batch) == batch_size:\n",
        "            \n",
        "            batch = []\n",
        "            mask = []\n",
        "            \n",
        "            for li in cur_batch:\n",
        "\n",
        "                tensor = line_to_tensor(li)\n",
        "\n",
        "                pad = [0] * (max_length - len(tensor))\n",
        "                tensor_pad = tensor + pad\n",
        "                batch.append(tensor_pad)\n",
        "\n",
        "                example_mask = [0 if t == 0 else 1 for t in tensor_pad]\n",
        "                mask.append(example_mask)\n",
        "               \n",
        "            batch_np_arr = np.array(batch)\n",
        "            mask_np_arr = np.array(mask)\n",
        "            \n",
        "            \n",
        "            yield batch_np_arr, batch_np_arr, mask_np_arr\n",
        "            \n",
        "            cur_batch = []\n",
        "            "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.113922,
          "end_time": "2020-10-19T05:24:57.728762",
          "exception": false,
          "start_time": "2020-10-19T05:24:57.614840",
          "status": "completed"
        },
        "tags": [],
        "id": "biglhqPjnr0s"
      },
      "source": [
        "# Defining the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.110544,
          "end_time": "2020-10-19T05:24:57.950897",
          "exception": false,
          "start_time": "2020-10-19T05:24:57.840353",
          "status": "completed"
        },
        "tags": [],
        "id": "6JgMdnTonr0s"
      },
      "source": [
        "## Gated Recurrent Unit\n",
        "\n",
        "This function generates a GRU Language Model, consisting of the following layers:\n",
        "\n",
        "* ShiftRight()\n",
        "* Embedding()\n",
        "* GRU Units(Number specified by the `n_layers` parameter)\n",
        "* Dense() Layer\n",
        "* LogSoftmax() Activation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-19T05:24:58.183193Z",
          "iopub.status.busy": "2020-10-19T05:24:58.182383Z",
          "iopub.status.idle": "2020-10-19T05:24:58.186370Z",
          "shell.execute_reply": "2020-10-19T05:24:58.185685Z"
        },
        "papermill": {
          "duration": 0.124594,
          "end_time": "2020-10-19T05:24:58.186525",
          "exception": false,
          "start_time": "2020-10-19T05:24:58.061931",
          "status": "completed"
        },
        "tags": [],
        "id": "MSA3bpCHnr0s"
      },
      "source": [
        "def GRULM(vocab_size=256, d_model=512, n_layers=2, mode='train'):\n",
        "    model = tl.Serial(\n",
        "      tl.ShiftRight(mode=mode),                                 \n",
        "      tl.Embedding( vocab_size = vocab_size, d_feature = d_model), \n",
        "      [tl.GRU(n_units=d_model) for _ in range(n_layers)], \n",
        "      tl.Dense(n_units = vocab_size), \n",
        "      tl.LogSoftmax() \n",
        "    )\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.150132,
          "end_time": "2020-10-19T05:24:58.463252",
          "exception": false,
          "start_time": "2020-10-19T05:24:58.313120",
          "status": "completed"
        },
        "tags": [],
        "id": "9A0JtfgCnr0s"
      },
      "source": [
        "## Long Short Term Memory\n",
        "\n",
        "This function generates a LSTM Language Model, consisting of the following layers:\n",
        "\n",
        "* ShiftRight()\n",
        "* Embedding()\n",
        "* LSTM Units(Number specified by the `n_layers` parameter)\n",
        "* Dense() Layer\n",
        "* LogSoftmax() Activation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-19T05:24:58.713423Z",
          "iopub.status.busy": "2020-10-19T05:24:58.712488Z",
          "iopub.status.idle": "2020-10-19T05:24:58.717162Z",
          "shell.execute_reply": "2020-10-19T05:24:58.716096Z"
        },
        "papermill": {
          "duration": 0.129976,
          "end_time": "2020-10-19T05:24:58.717410",
          "exception": false,
          "start_time": "2020-10-19T05:24:58.587434",
          "status": "completed"
        },
        "tags": [],
        "id": "ScuXPmvLnr0s"
      },
      "source": [
        "def LSTMLM(vocab_size=256, d_model=512, n_layers=2, mode='train'):\n",
        "    model = tl.Serial(\n",
        "      tl.ShiftRight(mode=mode),                                 \n",
        "      tl.Embedding( vocab_size = vocab_size, d_feature = d_model), \n",
        "      [tl.LSTM(n_units=d_model) for _ in range(n_layers)], \n",
        "      tl.Dense(n_units = vocab_size), \n",
        "      tl.LogSoftmax() \n",
        "    )\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.130305,
          "end_time": "2020-10-19T05:24:58.971978",
          "exception": false,
          "start_time": "2020-10-19T05:24:58.841673",
          "status": "completed"
        },
        "tags": [],
        "id": "zWVaUwG1nr0s"
      },
      "source": [
        "## Simple Recurrent Unit\n",
        "\n",
        "This function generates a SRU Language Model, consisting of the following layers:\n",
        "\n",
        "* ShiftRight()\n",
        "* Embedding()\n",
        "* SRU Units(Number specified by the `n_layers` parameter)\n",
        "* Dense() Layer\n",
        "* LogSoftmax() Activation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-19T05:24:59.219038Z",
          "iopub.status.busy": "2020-10-19T05:24:59.218146Z",
          "iopub.status.idle": "2020-10-19T05:24:59.221200Z",
          "shell.execute_reply": "2020-10-19T05:24:59.221764Z"
        },
        "papermill": {
          "duration": 0.12795,
          "end_time": "2020-10-19T05:24:59.221979",
          "exception": false,
          "start_time": "2020-10-19T05:24:59.094029",
          "status": "completed"
        },
        "tags": [],
        "id": "ECzZRknPnr0s"
      },
      "source": [
        "def SRULM(vocab_size=256, d_model=512, n_layers=2, mode='train'):\n",
        "    model = tl.Serial(\n",
        "      tl.ShiftRight(mode=mode),                                 \n",
        "      tl.Embedding( vocab_size = vocab_size, d_feature = d_model), \n",
        "      [tl.SRU(n_units=d_model) for _ in range(n_layers)], \n",
        "      tl.Dense(n_units = vocab_size), \n",
        "      tl.LogSoftmax() \n",
        "    )\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-19T05:24:59.461999Z",
          "iopub.status.busy": "2020-10-19T05:24:59.460669Z",
          "iopub.status.idle": "2020-10-19T05:24:59.465622Z",
          "shell.execute_reply": "2020-10-19T05:24:59.466443Z"
        },
        "papermill": {
          "duration": 0.132413,
          "end_time": "2020-10-19T05:24:59.466681",
          "exception": false,
          "start_time": "2020-10-19T05:24:59.334268",
          "status": "completed"
        },
        "tags": [],
        "id": "1i8UlSvhnr0s",
        "outputId": "f4894449-5399-48c8-e22d-a8fa05be3615"
      },
      "source": [
        "GRUmodel = GRULM(n_layers = 5)\n",
        "LSTMmodel = LSTMLM(n_layers = 5)\n",
        "SRUmodel = SRULM(n_layers = 5)\n",
        "print(GRUmodel)\n",
        "print(LSTMmodel)\n",
        "print(SRUmodel)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Serial[\n",
            "  ShiftRight(1)\n",
            "  Embedding_256_512\n",
            "  GRU_512\n",
            "  GRU_512\n",
            "  GRU_512\n",
            "  GRU_512\n",
            "  GRU_512\n",
            "  Dense_256\n",
            "  LogSoftmax\n",
            "]\n",
            "Serial[\n",
            "  ShiftRight(1)\n",
            "  Embedding_256_512\n",
            "  LSTM_512\n",
            "  LSTM_512\n",
            "  LSTM_512\n",
            "  LSTM_512\n",
            "  LSTM_512\n",
            "  Dense_256\n",
            "  LogSoftmax\n",
            "]\n",
            "Serial[\n",
            "  ShiftRight(1)\n",
            "  Embedding_256_512\n",
            "  SRU_512\n",
            "  SRU_512\n",
            "  SRU_512\n",
            "  SRU_512\n",
            "  SRU_512\n",
            "  Dense_256\n",
            "  LogSoftmax\n",
            "]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.117255,
          "end_time": "2020-10-19T05:24:59.712882",
          "exception": false,
          "start_time": "2020-10-19T05:24:59.595627",
          "status": "completed"
        },
        "tags": [],
        "id": "As2O2Zj8nr0t"
      },
      "source": [
        "## Hyperparameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.113458,
          "end_time": "2020-10-19T05:24:59.939569",
          "exception": false,
          "start_time": "2020-10-19T05:24:59.826111",
          "status": "completed"
        },
        "tags": [],
        "id": "cxIs1y_Gnr0t"
      },
      "source": [
        "Here, we declare `the batch_size` and the `max_length` hyperparameters for the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-19T05:25:00.173212Z",
          "iopub.status.busy": "2020-10-19T05:25:00.172118Z",
          "iopub.status.idle": "2020-10-19T05:25:00.176348Z",
          "shell.execute_reply": "2020-10-19T05:25:00.175587Z"
        },
        "papermill": {
          "duration": 0.121757,
          "end_time": "2020-10-19T05:25:00.176474",
          "exception": false,
          "start_time": "2020-10-19T05:25:00.054717",
          "status": "completed"
        },
        "tags": [],
        "id": "BLKz_gfKnr0t"
      },
      "source": [
        "batch_size = 32\n",
        "max_length = 64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.111425,
          "end_time": "2020-10-19T05:25:00.399880",
          "exception": false,
          "start_time": "2020-10-19T05:25:00.288455",
          "status": "completed"
        },
        "tags": [],
        "id": "zUKNlXAmnr0t"
      },
      "source": [
        "# Creating Evaluation and Training Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-19T05:25:00.637648Z",
          "iopub.status.busy": "2020-10-19T05:25:00.634400Z",
          "iopub.status.idle": "2020-10-19T05:25:00.641032Z",
          "shell.execute_reply": "2020-10-19T05:25:00.641698Z"
        },
        "papermill": {
          "duration": 0.130539,
          "end_time": "2020-10-19T05:25:00.641885",
          "exception": false,
          "start_time": "2020-10-19T05:25:00.511346",
          "status": "completed"
        },
        "tags": [],
        "id": "TYJepc9Knr0t"
      },
      "source": [
        "eval_lines = lines[-1000:] # Create a holdout validation set\n",
        "lines = lines[:-1000] # Leave the rest for training"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.112994,
          "end_time": "2020-10-19T05:25:00.871007",
          "exception": false,
          "start_time": "2020-10-19T05:25:00.758013",
          "status": "completed"
        },
        "tags": [],
        "id": "1DbI1fFSnr0t"
      },
      "source": [
        "# Training the Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.112218,
          "end_time": "2020-10-19T05:25:01.096544",
          "exception": false,
          "start_time": "2020-10-19T05:25:00.984326",
          "status": "completed"
        },
        "tags": [],
        "id": "8LKJoIzenr0t"
      },
      "source": [
        "Here, we create a function to train the models. This function does the following:\n",
        "\n",
        "* Creating a Train and Evaluation Generator that cycles infinetely using the `itertools` module\n",
        "* Train the Model using Adam Optimizer\n",
        "* Use the Accuracy Metric for Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-19T05:25:01.335062Z",
          "iopub.status.busy": "2020-10-19T05:25:01.330866Z",
          "iopub.status.idle": "2020-10-19T05:25:01.339390Z",
          "shell.execute_reply": "2020-10-19T05:25:01.338695Z"
        },
        "papermill": {
          "duration": 0.130503,
          "end_time": "2020-10-19T05:25:01.339549",
          "exception": false,
          "start_time": "2020-10-19T05:25:01.209046",
          "status": "completed"
        },
        "tags": [],
        "id": "i4-fSW3Tnr0t"
      },
      "source": [
        "from trax.supervised import training\n",
        "import itertools\n",
        "\n",
        "def train_model(model, data_generator, batch_size=32, max_length=64, lines=lines, eval_lines=eval_lines, n_steps=10, output_dir = 'model/'): \n",
        "\n",
        "    \n",
        "    bare_train_generator = data_generator(batch_size, max_length, data_lines=lines)\n",
        "    infinite_train_generator = itertools.cycle(bare_train_generator)\n",
        "    \n",
        "    bare_eval_generator = data_generator(batch_size, max_length, data_lines=eval_lines)\n",
        "    infinite_eval_generator = itertools.cycle(bare_eval_generator)\n",
        "   \n",
        "    train_task = training.TrainTask(\n",
        "        labeled_data=infinite_train_generator, \n",
        "        loss_layer=tl.CrossEntropyLoss(),   \n",
        "        optimizer=trax.optimizers.Adam(0.0005),\n",
        "        n_steps_per_checkpoint=1  \n",
        "    )\n",
        "\n",
        "    eval_task = training.EvalTask(\n",
        "        labeled_data=infinite_eval_generator,    \n",
        "        metrics=[tl.CrossEntropyLoss(), tl.Accuracy()],\n",
        "        n_eval_batches=1   \n",
        "    )\n",
        "    \n",
        "    training_loop = training.Loop(model,\n",
        "                                  train_task,\n",
        "                                  eval_tasks=[eval_task],\n",
        "                                  output_dir = output_dir\n",
        "                                  )\n",
        "\n",
        "    training_loop.run(n_steps=n_steps)\n",
        "    \n",
        "    return training_loop\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-19T05:25:01.602437Z",
          "iopub.status.busy": "2020-10-19T05:25:01.601617Z",
          "iopub.status.idle": "2020-10-19T05:26:21.063884Z",
          "shell.execute_reply": "2020-10-19T05:26:21.062700Z"
        },
        "papermill": {
          "duration": 79.597768,
          "end_time": "2020-10-19T05:26:21.064134",
          "exception": false,
          "start_time": "2020-10-19T05:25:01.466366",
          "status": "completed"
        },
        "tags": [],
        "id": "dykzx2t1nr0t"
      },
      "source": [
        "GRU_training_loop = train_model(GRUmodel, data_generator,n_steps=10, output_dir = 'model/GRU')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-19T05:26:21.431594Z",
          "iopub.status.busy": "2020-10-19T05:26:21.430465Z",
          "iopub.status.idle": "2020-10-19T05:27:55.049767Z",
          "shell.execute_reply": "2020-10-19T05:27:55.049034Z"
        },
        "papermill": {
          "duration": 93.801876,
          "end_time": "2020-10-19T05:27:55.049974",
          "exception": false,
          "start_time": "2020-10-19T05:26:21.248098",
          "status": "completed"
        },
        "tags": [],
        "id": "4w9jvGYDnr0t"
      },
      "source": [
        "LSTM_training_loop = train_model(LSTMmodel, data_generator, n_steps = 10, output_dir = 'model/LSTM')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-19T05:27:55.406482Z",
          "iopub.status.busy": "2020-10-19T05:27:55.405074Z",
          "iopub.status.idle": "2020-10-19T05:28:36.239692Z",
          "shell.execute_reply": "2020-10-19T05:28:36.238806Z"
        },
        "papermill": {
          "duration": 41.004194,
          "end_time": "2020-10-19T05:28:36.239938",
          "exception": false,
          "start_time": "2020-10-19T05:27:55.235744",
          "status": "completed"
        },
        "tags": [],
        "id": "PWePFGVKnr0t"
      },
      "source": [
        "SRU_training_loop = train_model(SRUmodel, data_generator, n_steps = 10, output_dir = 'model/SRU')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}