{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "name": "hourglass_downsampled_imagenet.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l0dbm8w-gdtU"
   },
   "source": [
    "#### Copyright 2021 Google LLC."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "HdZM-vAdgnmS"
   },
   "source": [
    "# Licensed under the Apache License, Version 2.0 (the \"License\")\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "07eztgeBgvFZ"
   },
   "source": [
    "# Hourglass: ImageNet32/64 evaluation [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/google/trax/blob/master/trax/models/research/examples/hourglass_downsampled_imagenet.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t1LRjNy473VX"
   },
   "source": [
    "### Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "yaqpNaQ4ShRP"
   },
   "source": [
    "!pip install -q --upgrade jaxlib==0.1.71+cuda111 -f https://storage.googleapis.com/jax-releases/jax_releases.html\n",
    "!pip install -q --upgrade jax==0.2.21\n",
    "!pip install -q git+https://github.com/google/trax.git\n",
    "!pip install -q pickle5\n",
    "!pip install -q gin"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "W0SxEBRxni_f"
   },
   "source": [
    "# Execute this for a proper TPU setup!\n",
    "# Make sure the Colab Runtime is set to Accelerator: TPU.\n",
    "import jax\n",
    "import requests\n",
    "import os\n",
    "if 'TPU_DRIVER_MODE' not in globals():\n",
    "    url = 'http://' + os.environ['COLAB_TPU_ADDR'].split(':')[0] + ':8475/requestversion/tpu_driver0.1-dev20200416'\n",
    "    resp = requests.post(url)\n",
    "    TPU_DRIVER_MODE = 1\n",
    "\n",
    "# The following is required to use TPU Driver as JAX's backend.\n",
    "from jax.config import config\n",
    "config.FLAGS.jax_xla_backend = \"tpu_driver\"\n",
    "config.FLAGS.jax_backend_target = \"grpc://\" + os.environ['COLAB_TPU_ADDR']\n",
    "print(config.FLAGS.jax_backend_target)\n",
    "jax.devices()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Uk7ByGL8Arl"
   },
   "source": [
    "### Download ImageNet32/64 data\n",
    "\n",
    "Downloading the datasets for evaluation requires some hacks because URLs from `tensorflow_datasets` are invalid. Two cells below download data for ImageNet32 and ImageNet64, respectively. Choose the one appropriate for the checkpoint you want to evaluate."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ZwLQV6p3qI0-"
   },
   "source": [
    "# Download ImageNet32 data (the url in tfds is down)\n",
    "!gdown https://drive.google.com/uc?id=1OV4lBnuIcbqeuoiK83jWtlnQ9Afl6Tsr\n",
    "!tar -zxf /content/im32.tar.gz\n",
    "\n",
    "# tfds hack for imagenet32\n",
    "import json\n",
    "json_path = '/content/content/drive/MyDrive/imagenet/downsampled_imagenet/32x32/2.0.0/dataset_info.json'\n",
    "with open(json_path, mode='r') as f:\n",
    "    ds_info = json.load(f)\n",
    "    if 'moduleName' in ds_info:\n",
    "        del ds_info['moduleName']\n",
    "with open(json_path, mode='w') as f:\n",
    "    json.dump(ds_info, f)\n",
    "\n",
    "!mkdir -p /root/tensorflow_datasets/downsampled_imagenet/32x32\n",
    "!cp -r /content/content/drive/MyDrive/imagenet/downsampled_imagenet/32x32/2.0.0 /root/tensorflow_datasets/downsampled_imagenet/32x32"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "No4xOawdVZKX"
   },
   "source": [
    "# Download  and set up ImageNet64 (validation only) data\n",
    "!gdown https://drive.google.com/uc?id=1ZoI3ZKMUXfrIlqPfIBCcegoe0aJHchpo\n",
    "\n",
    "!tar -zxf im64_valid.tar.gz\n",
    "!mkdir -p /root/tensorflow_datasets/downsampled_imagenet/64x64/2.0.0\n",
    "!cp im64_valid/* /root/tensorflow_datasets/downsampled_imagenet/64x64/2.0.0"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "CtdK1AocUoDd"
   },
   "source": [
    "# Download gin configs\n",
    "!wget -q https://raw.githubusercontent.com/google/trax/master/trax/supervised/configs/hourglass_imagenet32.gin\n",
    "!wget -q https://raw.githubusercontent.com/google/trax/master/trax/supervised/configs/hourglass_imagenet64.gin"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F6HqQDCF8WUL"
   },
   "source": [
    "### Load the ImageNet32 model\n",
    "\n",
    "This colab can be used to evaluate both imagenet32 and imagenet64 models. We start with our ImageNet32 checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "JdwK-HxB2kDT"
   },
   "source": [
    "import gin\n",
    "gin.parse_config_file('hourglass_imagenet32.gin')\n",
    "\n",
    "model = trax.models.HourglassLM(mode='eval')\n",
    "model.init_from_file(\n",
    "    'gs://trax-ml/hourglass/imagenet32/model_470000.pkl.gz',\n",
    "    weights_only=True,\n",
    ")\n",
    "\n",
    "loss_fn = trax.layers.WeightedCategoryCrossEntropy()\n",
    "model_eval = trax.layers.Accelerate(trax.layers.Serial(\n",
    "    model,\n",
    "    loss_fn\n",
    "))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T4qFd8CUXOht"
   },
   "source": [
    "### Evaluate on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Pq3oOJudlD7m"
   },
   "source": [
    "import gin\n",
    "import trax\n",
    "\n",
    "# Here is the hacky part to remove shuffling of the dataset\n",
    "def get_eval_dataset():\n",
    "    dataset_name = gin.query_parameter('data_streams.dataset_name')\n",
    "    data_dir = trax.data.tf_inputs.download_and_prepare(dataset_name, None)\n",
    "\n",
    "    train_data, eval_data, keys = trax.data.tf_inputs._train_and_eval_dataset(\n",
    "        dataset_name, data_dir, eval_holdout_size=0)\n",
    "\n",
    "    bare_preprocess_fn = gin.query_parameter('data_streams.bare_preprocess_fn')\n",
    "\n",
    "    eval_data = bare_preprocess_fn.scoped_configurable_fn(eval_data, training=False)\n",
    "\n",
    "    return trax.fastmath.dataset_as_numpy(eval_data)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ePcAbdRyk__V"
   },
   "source": [
    "from trax import fastmath\n",
    "from trax.fastmath import numpy as jnp\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def batched_inputs(data_gen, batch_size):\n",
    "  inp_stack, mask_stack = [], []\n",
    "\n",
    "  for input_example, mask in data_gen:\n",
    "    inp_stack.append(input_example)\n",
    "    mask_stack.append(mask)\n",
    "    if len(inp_stack) % batch_size == 0:\n",
    "      if len(set(len(example) for example in inp_stack)) > 1:\n",
    "        for x, m in zip(inp_stack, mask_stack):\n",
    "          yield x, m\n",
    "      else:\n",
    "        input_batch = jnp.stack(inp_stack)\n",
    "        mask_batch = jnp.stack(mask_stack)\n",
    "\n",
    "        yield input_batch, mask_batch\n",
    "      inp_stack, mask_stack = [], []\n",
    "\n",
    "  if len(inp_stack) > 0:\n",
    "    for inp, mask in zip(inp_stack, mask_stack):\n",
    "      yield inp, mask\n",
    "\n",
    "\n",
    "def run_full_evaluation(accelerated_model_with_loss, examples_data_gen,\n",
    "                        batch_size, pad_to_len=None):\n",
    "  # Important: we assume batch size per device = 1\n",
    "  assert batch_size % fastmath.local_device_count() == 0\n",
    "  assert fastmath.local_device_count() == 1 or \\\n",
    "         batch_size == fastmath.local_device_count()\n",
    "\n",
    "  loss_sum, n_tokens = 0.0, 0\n",
    "\n",
    "  def pad_right(inp_tensor):\n",
    "    if pad_to_len:\n",
    "      return jnp.pad(inp_tensor,\n",
    "                     [[0, 0], [0, max(0, pad_to_len - inp_tensor.shape[1])]])\n",
    "    else:\n",
    "      return inp_tensor\n",
    "\n",
    "  batch_gen = batched_inputs(examples_data_gen, batch_size)\n",
    "\n",
    "  def batch_leftover_example(input_example, example_mask):\n",
    "    def extend_shape_to_batch_size(tensor):\n",
    "      return jnp.repeat(tensor, repeats=batch_size, axis=0)\n",
    "\n",
    "    return map(extend_shape_to_batch_size,\n",
    "               (input_example[None, ...], example_mask[None, ...]))\n",
    "\n",
    "  for i, (inp, mask) in tqdm(enumerate(batch_gen)):\n",
    "    leftover_batch = False\n",
    "    if len(inp.shape) == 1:\n",
    "      inp, mask = batch_leftover_example(inp, mask)\n",
    "      leftover_batch = True\n",
    "\n",
    "    inp, mask = map(pad_right, [inp, mask])\n",
    "\n",
    "    example_losses = accelerated_model_with_loss((inp, inp, mask))\n",
    "\n",
    "    if leftover_batch:\n",
    "      example_losses = example_losses[:1]\n",
    "      mask = mask[:1]\n",
    "\n",
    "    example_lengths = mask.sum(axis=-1)\n",
    "\n",
    "    loss_sum += (example_lengths * example_losses).sum()\n",
    "    n_tokens += mask.sum()\n",
    "\n",
    "    if i % 200 == 0:\n",
    "      print(f'Batches: {i}, current loss: {loss_sum / float(n_tokens)}')\n",
    "\n",
    "  return loss_sum / float(n_tokens)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BPo6MMkSQ4l0"
   },
   "source": [
    "# ImageNet32 evaluation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "jf8Ju2hImGs9"
   },
   "source": [
    "def data_gen(dataset):\n",
    "    for example in dataset:\n",
    "        example = example['image']\n",
    "        mask = jnp.ones_like(example)\n",
    "        yield example, mask\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "eval_data_gen = data_gen(get_eval_dataset())\n",
    "\n",
    "loss = run_full_evaluation(model_eval, eval_data_gen, BATCH_SIZE)\n",
    "print(f'Final perplexity: {loss}, final bpd: {loss / jnp.log(2)}')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QNLx69lGVi_5"
   },
   "source": [
    "# ImageNet64 evaluation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "haW0O664Q6JU"
   },
   "source": [
    "gin.parse_config_file('hourglass_imagenet64.gin')\n",
    "\n",
    "model = trax.models.HourglassLM(mode='eval')\n",
    "model.init_from_file(\n",
    "    'gs://trax-ml/hourglass/imagenet64/model_300000.pkl.gz',\n",
    "    weights_only=True,\n",
    ")\n",
    "\n",
    "loss_fn = trax.layers.WeightedCategoryCrossEntropy()\n",
    "model_eval = trax.layers.Accelerate(trax.layers.Serial(\n",
    "    model,\n",
    "    loss_fn\n",
    "))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "It0inD1ZVhqF"
   },
   "source": [
    "BATCH_SIZE = 8\n",
    "eval_data_gen = data_gen(get_eval_dataset())\n",
    "\n",
    "loss = run_full_evaluation(model_eval, eval_data_gen, BATCH_SIZE)\n",
    "print(f'Final perplexity: {loss}, final bpd: {loss / jnp.log(2)}')"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}