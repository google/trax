{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6NWA5uxOmBVz"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "# Copyright 2020 Google LLC.\n",
    "\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OLUMD0tPP6Hd"
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import functools\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import psutil\n",
    "from absl import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For example, if trax is inside a 'src' directory\n",
    "project_root = os.environ.get('TRAX_PROJECT_ROOT', '')\n",
    "sys.path.insert(0, project_root)\n",
    "\n",
    "# Option to verify the import path\n",
    "print(f\"Python will look for packages in: {sys.path[0]}\")\n",
    "\n",
    "# Import trax\n",
    "import trax\n",
    "from trax import fastmath\n",
    "from trax import layers as tl\n",
    "from trax.fastmath import numpy as jnp\n",
    "from trax.learning.supervised import training\n",
    "\n",
    "# Verify the source of the imported package\n",
    "print(f\"Imported trax from: {trax.__file__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nG4CK5NsP6He"
   },
   "outputs": [],
   "source": [
    "class MyLoop(training.Loop):\n",
    "    def __init__(\n",
    "            self,\n",
    "            *args, **kwargs\n",
    "    ):\n",
    "        super().__init__(\n",
    "            *args, **kwargs\n",
    "        )\n",
    "        self._stop_training = False\n",
    "\n",
    "    def run(self, n_steps=1):\n",
    "        \"\"\"Just add a logic to break the loop to ``training.Loop.run`` when\n",
    "            the early stopping condition is satisfied.\n",
    "        \"\"\"\n",
    "\n",
    "        with self._open_summary_writers() as (\n",
    "                train_summary_writers,\n",
    "                eval_summary_writers,\n",
    "        ):\n",
    "            process = psutil.Process(os.getpid())\n",
    "            loss_acc, step_acc = 0.0, 0\n",
    "            start_time = time.time()\n",
    "            optimizer_metrics_acc = collections.defaultdict(float)\n",
    "            for i in range(n_steps):\n",
    "                prev_task_index = self._which_task(self._step)\n",
    "                self._step += 1\n",
    "                task_index = self._which_task(self._step)\n",
    "                task_changed = task_index != prev_task_index\n",
    "\n",
    "                if task_changed:\n",
    "                    loss_acc, step_acc = 0.0, 0\n",
    "\n",
    "                loss, optimizer_metrics = self._run_one_step(task_index, task_changed)\n",
    "\n",
    "                optimizer_metrics, loss = fastmath.nested_map(\n",
    "                    functools.partial(tl.mean, self._n_devices),\n",
    "                    (optimizer_metrics, loss),\n",
    "                )\n",
    "\n",
    "                loss_acc += loss\n",
    "                # Log loss every 50 steps, every step in memory-efficient trainers.\n",
    "                if self._step % 50 == 0 or self._use_memory_efficient_trainer:\n",
    "                    self._log_step(\"Loss: %.4f\" % loss, stdout=False)\n",
    "                step_acc += 1\n",
    "                for metric_name, value in optimizer_metrics.items():\n",
    "                    optimizer_metrics_acc[metric_name] += value\n",
    "\n",
    "                if self._checkpoint_at(self.step):\n",
    "                    self.save_checkpoint(\"model\")\n",
    "                if self._permanent_checkpoint_at(self.step):\n",
    "                    self.save_checkpoint(f\"model_{self.step}\")\n",
    "                if self._eval_at(self.step):\n",
    "                    logging.info(\n",
    "                        \"cpu memory use (MB): %.2f\",\n",
    "                        process.memory_info().rss / float(1024 * 1024),\n",
    "                    )\n",
    "                    elapsed_time = time.time() - start_time\n",
    "                    self._log_training_progress(\n",
    "                        task=self._tasks[task_index],\n",
    "                        total_loss=loss_acc,\n",
    "                        n_steps=step_acc,\n",
    "                        elapsed_time=elapsed_time,\n",
    "                        optimizer_metrics=optimizer_metrics_acc,\n",
    "                        summary_writer=train_summary_writers[task_index],\n",
    "                    )\n",
    "                    self.run_evals(eval_summary_writers)\n",
    "                    loss_acc, step_acc = 0.0, 0\n",
    "                    start_time = time.time()\n",
    "                    optimizer_metrics_acc = collections.defaultdict(float)\n",
    "\n",
    "                if self._checkpoint_at(self.step):\n",
    "                    if self._checkpoint_low_metric is not None and self._at_lowest():\n",
    "                        self.save_checkpoint(f\"lowest_{self._checkpoint_low_metric}\")\n",
    "                    if self._checkpoint_high_metric is not None and self._at_highest():\n",
    "                        self.save_checkpoint(f\"highest_{self._checkpoint_high_metric}\")\n",
    "\n",
    "                for callback in self._callbacks:\n",
    "                    if callback.call_at(self.step):\n",
    "                        if callback.__class__.__name__ == 'EarlyStopping':\n",
    "                            #added to check for earlystopping callback after\n",
    "                            # history was updated.\n",
    "                            #callback.on_step_end execute before history was\n",
    "                            #updated.\n",
    "                            best_step = callback.on_step_begin_with_history(self.step)\n",
    "\n",
    "                            if not self._stop_training and self.step == n_steps:\n",
    "                                self._log_step(\"Did not meet early stopping condition.\")\n",
    "\n",
    "                if self._stop_training:\n",
    "                    # added to stop the training.\n",
    "                    self._log_step(f\"Early stopping... \"\n",
    "                                   f\" the best step at {best_step}\")\n",
    "                    break\n",
    "\n",
    "        self._eval_model.weights = self._model.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rfncVhM7P6Hg"
   },
   "outputs": [],
   "source": [
    "def callback_earlystopper(\n",
    "        monitor=None,\n",
    "        min_delta=0,\n",
    "        patience=0,\n",
    "        mode=\"auto\",\n",
    "        restore_best_checkpoint=True\n",
    "):\n",
    "    \"\"\"Wrap the EarlyStopping class into a callable.\n",
    "\n",
    "    Returns an early stopping.\n",
    "\n",
    "    Args:\n",
    "    monitor: Quantity to be monitored.\n",
    "\n",
    "    min_delta: Minimum change in the monitored quantity\n",
    "        to qualify as an improvement, i.e. an absolute\n",
    "        change of less than min_delta, will count as no\n",
    "        improvement.\n",
    "\n",
    "    patience: ``patience`` times ``n_steps_per_checkpoint`` will be\n",
    "        the total number of steps without improvement\n",
    "        after which training will be stopped.\n",
    "\n",
    "    mode: One of ``{\"auto\", \"min\", \"max\"}``. In ``min``(``max``) mode,\n",
    "        training will stop when the quantity monitored has stopped\n",
    "        decreasing(increasing) during the number of steps assigned\n",
    "        in ``patience``; in ``\"auto\"``\n",
    "        mode, the direction is automatically inferred\n",
    "        from the name of the monitored quantity.\n",
    "\n",
    "    restore_best_checkpoint: Whether to restore model from\n",
    "        the checkpoint with the best value of the monitored quantity.\n",
    "        If False, the model weights obtained at the last step of\n",
    "        training are used. If True and there is an early stopping,\n",
    "        the best checkpoint will be restored.\n",
    "    \"\"\"\n",
    "\n",
    "    if mode not in [\"auto\", \"max\", \"min\"]:\n",
    "        self._loop._log_step(\n",
    "            f\"Early stopping mode='{mode}' is unknown, \" \"fallback to 'auto' mode\"\n",
    "        )\n",
    "        mode = \"auto\"\n",
    "\n",
    "    class EarlyStopping:\n",
    "        \"\"\"Create a call back taht activates early stopping.\n",
    "\n",
    "        Activate early stopping.\n",
    "        \"\"\"\n",
    "\n",
    "        def __init__(self, loop):\n",
    "            \"\"\"Configures an early stopping.\n",
    "            This is inspired by keras.callbacks.EarlyStopping.\n",
    "\n",
    "            Args:\n",
    "                loop:   training ``Loop`` from the current training.\n",
    "\n",
    "            \"\"\"\n",
    "\n",
    "            self._loop = loop\n",
    "            self.monitor = monitor\n",
    "            self.min_delta = jnp.abs(min_delta)\n",
    "            self.patience = jnp.maximum(patience, 1)\n",
    "\n",
    "            self.restore_best_checkpoint = restore_best_checkpoint\n",
    "\n",
    "            if mode == \"min\":\n",
    "                self.monitor_op = jnp.less\n",
    "            elif mode == \"max\":\n",
    "                self.monitor_op = jnp.greater\n",
    "            else:\n",
    "                if self.monitor.endswith(\"Accuracy\"):\n",
    "                    self.monitor_op = jnp.greater\n",
    "                else:\n",
    "                    self.monitor_op = jnp.less\n",
    "\n",
    "            if self.monitor_op == np.greater:\n",
    "                self.min_delta *= 1\n",
    "            else:\n",
    "                self.min_delta *= -1\n",
    "\n",
    "            self.wait = 0\n",
    "            self.stopped_step = 1\n",
    "            self.best = jnp.inf if self.monitor_op == jnp.less else -jnp.inf\n",
    "            self.best_step = 1\n",
    "            self.best_checkpoint_path = None\n",
    "\n",
    "        def _is_metric_exist(self):\n",
    "            metric_names = [\n",
    "                name\n",
    "                for eval_task in self._loop._eval_tasks\n",
    "                for name in eval_task.metric_names\n",
    "            ]\n",
    "            return self.monitor in metric_names\n",
    "\n",
    "        def call_at(self, step):\n",
    "            return self._loop._eval_at(step)\n",
    "\n",
    "        def on_step_begin(self, step):\n",
    "            if not self._is_metric_exist():\n",
    "                # Raise error if the monitor name is not in evaluation task.\n",
    "                self._loop._log_step(\n",
    "                    f\"Early Stopping metric '{self.monitor}' \" \"is not in eval_tasks.\"\n",
    "                )\n",
    "                self._loop._log_step(\n",
    "                    \"Select one of \" f\"them from here {self.metric_names}.\"\n",
    "                )\n",
    "\n",
    "                raise SystemExit(\"Monitoring metric not found.\")\n",
    "\n",
    "        def on_step_end(self, step):\n",
    "            pass\n",
    "\n",
    "        def on_step_begin_with_history(self, step):\n",
    "            if self.restore_best_checkpoint and self.best_checkpoint_path is None:\n",
    "                self._loop.save_checkpoint(\"best_checkpoint\")\n",
    "                self.best_checkpoint_path = os.path.join(\n",
    "                    self._loop._output_dir, \"best_checkpoint.pkl.gz\"\n",
    "                )\n",
    "\n",
    "            self.wait += 1\n",
    "            current_step, current = self._get_monitor_value()\n",
    "\n",
    "            if current is None:\n",
    "                return\n",
    "\n",
    "            if self._is_improvement(current, self.best):\n",
    "                self.best = current\n",
    "                self.best_step = current_step\n",
    "                self._loop.save_checkpoint(\"best_checkpoint\")\n",
    "\n",
    "                # reset wait\n",
    "                self.wait = 0\n",
    "\n",
    "            if self.wait >= self.patience and step > 1:\n",
    "                self.stopped_step = current_step\n",
    "                self._loop._stop_training = True\n",
    "\n",
    "                if (\n",
    "                        self.restore_best_checkpoint\n",
    "                        and self.best_checkpoint_path is not None\n",
    "                ):\n",
    "                    self._loop.load_checkpoint(self.best_checkpoint_path)\n",
    "                    self._loop._log_step(\n",
    "                        f\"Best checkpoint was restored from Step {self.best_step}.\"\n",
    "                    )\n",
    "\n",
    "                return self.best_step\n",
    "\n",
    "        def _is_improvement(self, monitor_value, reference_value):\n",
    "            return self.monitor_op(monitor_value - self.min_delta, reference_value)\n",
    "\n",
    "        def _get_monitor_value(self):\n",
    "            step, monitor_value = self._loop.history.get(\n",
    "                \"eval\", \"metrics/\" + self.monitor\n",
    "            )[-1]\n",
    "            return step, monitor_value\n",
    "\n",
    "    return EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sJHUx_nSP6Hh"
   },
   "source": [
    "## Linear Regression\n",
    "## Generate data for linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dKYZQY-pP6Hi"
   },
   "outputs": [],
   "source": [
    "def get_data_linear():\n",
    "    while True:\n",
    "        x = np.random.randint(low=1, high=10) * 1.0\n",
    "        y = x * 2.0 - 1\n",
    "        yield (np.array([x]), np.array([y]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SCTZW1pBP6Hj"
   },
   "outputs": [],
   "source": [
    "data_linear = get_data_linear()\n",
    "print(next(data_linear))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4pcAhWJMP6Hk"
   },
   "outputs": [],
   "source": [
    "from trax.data.preprocessing import inputs as preprocessing\n",
    "\n",
    "data_pipeline = preprocessing.Serial(preprocessing.Batch(50), preprocessing.AddLossWeights(), )\n",
    "data_stream = data_pipeline(data_linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2vK15-1oP6Hl"
   },
   "source": [
    "## Build a simple linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xzN0oZBCP6Hl"
   },
   "outputs": [],
   "source": [
    "model_linear = tl.Serial(tl.Dense(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qi0bM41PP6Hl"
   },
   "source": [
    "## Train a linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d0_9qZHVP6Hm"
   },
   "outputs": [],
   "source": [
    "from trax import optimizers as optimizers\n",
    "\n",
    "# Use the same data_stream for both training and evaluation\n",
    "train_task = training.TrainTask(\n",
    "    labeled_data=data_stream,\n",
    "    loss_layer=tl.L2Loss(),\n",
    "    optimizer=optimizers.SGD(0.01),\n",
    "    n_steps_per_checkpoint=10,\n",
    ")\n",
    "\n",
    "eval_task = training.EvalTask(\n",
    "    labeled_data=data_stream, metrics=[tl.L2Loss()], n_eval_batches=15,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R5ngyoYSP6Hm"
   },
   "source": [
    "## Add early stopping function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SKetNF4LP6Hm"
   },
   "outputs": [],
   "source": [
    "earlystopping = callback_earlystopper(monitor='L2Loss', min_delta=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D2XjQO80P6Hn"
   },
   "outputs": [],
   "source": [
    "# Delete the training folder\n",
    "!rm -r linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mCrc_bXZP6Hn"
   },
   "outputs": [],
   "source": [
    "model_linear = tl.Serial(tl.Dense(1))\n",
    "training_loop = MyLoop(\n",
    "    model=model_linear, tasks=train_task, eval_tasks=[eval_task], output_dir=\"./linear_model\",\n",
    "    callbacks=[earlystopping]\n",
    ")\n",
    "# training_loop.save_checkpoint(f'step_{training_loop.step}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kFURD6T4P6Hn"
   },
   "outputs": [],
   "source": [
    "training_loop.run(1500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lg_ONworP6Hn"
   },
   "source": [
    "## Change patience\n",
    "patience = 10 means it will wait for 10 x 10 = 100 steps (patience * n_steps_per_checkpoint ) to before making a decision to stop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IStFKG7GP6Hn"
   },
   "outputs": [],
   "source": [
    "earlystopping = callback_earlystopper(monitor='L2Loss', patience=10, min_delta=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pihrcvTtP6Ho"
   },
   "outputs": [],
   "source": [
    "# Delete the training folder\n",
    "!rm -r linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UvjDLZd3P6Ho"
   },
   "outputs": [],
   "source": [
    "model_linear = tl.Serial(tl.Dense(1))\n",
    "training_loop = MyLoop(\n",
    "    model=model_linear, tasks=train_task, eval_tasks=[eval_task], output_dir=\"./linear_model\",\n",
    "    callbacks=[earlystopping]\n",
    ")\n",
    "# training_loop.save_checkpoint(f'step_{training_loop.step}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bAsft27BP6Ho"
   },
   "outputs": [],
   "source": [
    "training_loop.run(1500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6HyIjZWBP6Ho"
   },
   "source": [
    "## Make a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d7bVzat7P6Ho"
   },
   "outputs": [],
   "source": [
    "test_data = np.array([[2.0], [3.0], [10.0], [44.0]])\n",
    "model_linear(test_data)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "earlystopping.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
