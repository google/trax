{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7yuytuIllsv1"
   },
   "source": [
    "# Trax Quick Intro\n",
    "\n",
    "[Trax](https://trax-ml.readthedocs.io/en/latest/) is an end-to-end library for deep learning that focuses on clear code and speed. It is actively used and maintained in the [Google Brain team](https://research.google.com/teams/brain/). This notebook ([run it in colab](https://colab.research.google.com/github/google/trax/blob/master/trax/intro.ipynb)) shows how to use Trax and where you can find more information.\n",
    "\n",
    "  1. **Run a pre-trained Transformer**: create a translator in a few lines of code\n",
    "  1. **Features and resources**: [API docs](https://trax-ml.readthedocs.io/en/latest/trax.html), where to [talk to us](https://gitter.im/trax-ml/community), how to [open an issue](https://github.com/google/trax/issues) and more\n",
    "  1. **Walkthrough**: how Trax works, how to make new models and train on your own data\n",
    "\n",
    "We welcome **contributions** to Trax! We welcome PRs with code for new models and layers as well as improvements to our code and documentation. We especially love **notebooks** that explain how models work and show how to use them to solve problems!\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BIl27504La0G"
   },
   "source": [
    "**General Setup**\n",
    "\n",
    "Execute the following few cells (once) before running any of the code samples."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "executionInfo": {
     "elapsed": 36794,
     "status": "ok",
     "timestamp": 1607149386661,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "oILRLCWN_16u",
    "ExecuteTime": {
     "end_time": "2025-04-10T08:30:38.464836Z",
     "start_time": "2025-04-10T08:30:38.457491Z"
    }
   },
   "source": [
    "#@title\n",
    "# Copyright 2020 Google LLC.\n",
    "\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ],
   "outputs": [],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 463,
     "status": "ok",
     "timestamp": 1607149387132,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "vlGjGoGMTt-D",
    "outputId": "3076e638-695d-4017-e757-98d929630e17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: pip: command not found\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T08:30:41.534195Z",
     "start_time": "2025-04-10T08:30:41.523486Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# For example, if trax is inside a 'src' directory\n",
    "project_root = os.environ.get('TRAX_PROJECT_ROOT', '')\n",
    "sys.path.insert(0, project_root)\n",
    "\n",
    "# Option to verify the import path\n",
    "print(f\"Python will look for packages in: {sys.path[0]}\")\n",
    "\n",
    "# Import trax\n",
    "import trax\n",
    "from trax.data.encoder import encoder\n",
    "from trax.learning.supervised import decoding as decoding\n",
    "from trax import models as models\n",
    "\n",
    "# Verify the source of the imported package\n",
    "print(f\"Imported trax from: {trax.__file__}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python will look for packages in: \n",
      "Imported trax from: /raid/mmironczuk/projects/trax-upgrade/trax/__init__.py\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-LQ89rFFsEdk"
   },
   "source": [
    "## 1. Run a pre-trained Transformer\n",
    "\n",
    "Here is how you create an Engligh-German translator in a few lines of code:\n",
    "\n",
    "* create a Transformer model in Trax with [trax.models.Transformer](https://trax-ml.readthedocs.io/en/latest/trax.models.html#trax.models.transformer.Transformer)\n",
    "* initialize it from a file with pre-trained weights with [model.init_from_file](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.base.Layer.init_from_file)\n",
    "* tokenize your input sentence to input into the model with [trax.data.tokenize](https://trax-ml.readthedocs.io/en/latest/trax.data.html#trax.data.tf_inputs.tokenize)\n",
    "* decode from the Transformer with [trax.supervised.decoding.autoregressive_sample](https://trax-ml.readthedocs.io/en/latest/trax.supervised.html#trax.supervised.decoding.autoregressive_sample)\n",
    "* de-tokenize the decoded result to get the translation with [trax.data.detokenize](https://trax-ml.readthedocs.io/en/latest/trax.data.html#trax.data.tf_inputs.detokenize)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "executionInfo": {
     "elapsed": 46373,
     "status": "ok",
     "timestamp": 1607149433512,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "djTiSLcaNFGa",
    "outputId": "a7917337-0a77-4064-8a6e-4e44e4a9c7c7",
    "ExecuteTime": {
     "end_time": "2025-04-10T08:31:46.191352Z",
     "start_time": "2025-04-10T08:31:01.676650Z"
    }
   },
   "source": [
    "# Create a Transformer model.\n",
    "# Pre-trained model config in gs://trax-ml/models/translation/ende_wmt32k.gin\n",
    "model = models.Transformer(\n",
    "    input_vocab_size=33300,\n",
    "    d_model=512, d_ff=2048,\n",
    "    n_heads=8, n_encoder_layers=6, n_decoder_layers=6,\n",
    "    max_len=2048, mode='predict')\n",
    "\n",
    "# Initialize using pre-trained weights.\n",
    "model.init_from_file('gs://trax-ml/models/translation/ende_wmt32k.pkl.gz',\n",
    "                     weights_only=True)\n",
    "\n",
    "# Tokenize a sentence.\n",
    "sentence = 'It is nice to learn new things today!'\n",
    "tokenized = list(encoder.tokenize(iter([sentence]),  # Operates on streams.\n",
    "                                  vocab_dir='gs://trax-ml/vocabs/',\n",
    "                                  vocab_file='ende_32k.subword'))[0]\n",
    "\n",
    "# Decode from the Transformer.\n",
    "tokenized = tokenized[None, :]  # Add batch dimension.\n",
    "tokenized_translation = decoding.autoregressive_sample(\n",
    "    model, tokenized, temperature=0.0)  # Higher temperature: more diverse results.\n",
    "\n",
    "# De-tokenize,\n",
    "tokenized_translation = tokenized_translation[0][:-1]  # Remove batch and EOS.\n",
    "translation = encoder.detokenize(tokenized_translation,\n",
    "                                 vocab_dir='gs://trax-ml/vocabs/',\n",
    "                                 vocab_file='ende_32k.subword')\n",
    "print(translation)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Es ist schÃ¶n, heute neue Dinge zu lernen!\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QMo3OnsGgLNK"
   },
   "source": [
    "## 2. Features and resources\n",
    "\n",
    "Trax includes basic models (like [ResNet](https://github.com/google/trax/blob/master/trax/models/resnet.py#L70), [LSTM](https://github.com/google/trax/blob/master/trax/models/rnn.py#L100), [Transformer](https://github.com/google/trax/blob/master/trax/models/transformer.py#L189) and RL algorithms\n",
    "(like [REINFORCE](https://github.com/google/trax/blob/master/trax/rl/training.py#L244), [A2C](https://github.com/google/trax/blob/master/trax/rl/actor_critic_joint.py#L458), [PPO](https://github.com/google/trax/blob/master/trax/rl/actor_critic_joint.py#L209)). It is also actively used for research and includes\n",
    "new models like the [Reformer](https://github.com/google/trax/tree/master/trax/models/reformer) and new RL algorithms like [AWR](https://arxiv.org/abs/1910.00177). Trax has bindings to a large number of deep learning datasets, including\n",
    "[Tensor2Tensor](https://github.com/tensorflow/tensor2tensor) and [TensorFlow datasets](https://www.tensorflow.org/datasets/catalog/overview).\n",
    "\n",
    "\n",
    "You can use Trax either as a library from your own python scripts and notebooks\n",
    "or as a binary from the shell, which can be more convenient for training large models.\n",
    "It runs without any changes on CPUs, GPUs and TPUs.\n",
    "\n",
    "* [API docs](https://trax-ml.readthedocs.io/en/latest/)\n",
    "* [chat with us](https://gitter.im/trax-ml/community)\n",
    "* [open an issue](https://github.com/google/trax/issues)\n",
    "* subscribe to [trax-discuss](https://groups.google.com/u/1/g/trax-discuss) for news\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8wgfJyhdihfR"
   },
   "source": [
    "## 3. Walkthrough\n",
    "\n",
    "You can learn here how Trax works, how to create new models and how to train them on your own data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yM12hgQnp4qo"
   },
   "source": [
    "### Tensors and Fast Math\n",
    "\n",
    "The basic units flowing through Trax models are *tensors* - multi-dimensional arrays, sometimes also known as numpy arrays, due to the most widely used package for tensor operations -- `numpy`. You should take a look at the [numpy guide](https://numpy.org/doc/stable/user/quickstart.html) if you don't know how to operate on tensors: Trax also uses the numpy API for that.\n",
    "\n",
    "In Trax we want numpy operations to run very fast, making use of GPUs and TPUs to accelerate them. We also want to automatically compute gradients of functions on tensors. This is done in the `trax.fastmath` package thanks to its backends -- [JAX](https://github.com/google/jax) and [TensorFlow numpy](https://tensorflow.org)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "executionInfo": {
     "elapsed": 667,
     "status": "ok",
     "timestamp": 1607149434186,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "kSauPt0NUl_o",
    "outputId": "c7288312-767d-4344-91ae-95ebf386ce57",
    "ExecuteTime": {
     "end_time": "2025-04-10T08:32:00.091107Z",
     "start_time": "2025-04-10T08:32:00.074272Z"
    }
   },
   "source": [
    "from trax.fastmath import numpy as fastnp\n",
    "\n",
    "trax.fastmath.use_backend('jax')  # Can be 'jax' or 'tensorflow-numpy'.\n",
    "\n",
    "matrix = fastnp.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "print(f'matrix =\\n{matrix}')\n",
    "vector = fastnp.ones(3)\n",
    "print(f'vector = {vector}')\n",
    "product = fastnp.dot(vector, matrix)\n",
    "print(f'product = {product}')\n",
    "tanh = fastnp.tanh(product)\n",
    "print(f'tanh(product) = {tanh}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matrix =\n",
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n",
      "vector = [1. 1. 1.]\n",
      "product = [12. 15. 18.]\n",
      "tanh(product) = [1. 1. 1.]\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "snLYtU6OsKU2"
   },
   "source": [
    "Gradients can be calculated using `trax.fastmath.grad`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "executionInfo": {
     "elapsed": 545,
     "status": "ok",
     "timestamp": 1607149434742,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "cqjYoxPEu8PG",
    "outputId": "04739509-9d3a-446d-d088-84882b8917bc",
    "ExecuteTime": {
     "end_time": "2025-04-10T08:32:02.989075Z",
     "start_time": "2025-04-10T08:32:02.965900Z"
    }
   },
   "source": [
    "def f(x):\n",
    "    return 2.0 * x * x\n",
    "\n",
    "\n",
    "grad_f = trax.fastmath.grad(f)\n",
    "\n",
    "print(f'grad(2x^2) at 1 = {grad_f(1.0)}')\n",
    "print(f'grad(2x^2) at -2 = {grad_f(-2.0)}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad(2x^2) at 1 = 4.0\n",
      "grad(2x^2) at -2 = -8.0\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p-wtgiWNseWw"
   },
   "source": [
    "### Layers\n",
    "\n",
    "Layers are basic building blocks of Trax models. You will learn all about them in the [layers intro](https://trax-ml.readthedocs.io/en/latest/notebooks/layers_intro.html) but for now, just take a look at the implementation of one core Trax layer, `Embedding`:\n",
    "\n",
    "```\n",
    "class Embedding(base.Layer):\n",
    "  \"\"\"Trainable layer that maps discrete tokens/IDs to vectors.\"\"\"\n",
    "\n",
    "  def __init__(self,\n",
    "               vocab_size,\n",
    "               d_feature,\n",
    "               kernel_initializer=init.RandomNormalInitializer(1.0)):\n",
    "    \"\"\"Returns an embedding layer with given vocabulary size and vector size.\n",
    "\n",
    "    Args:\n",
    "      vocab_size: Size of the input vocabulary. The layer will assign a unique\n",
    "          vector to each id in `range(vocab_size)`.\n",
    "      d_feature: Dimensionality/depth of the output vectors.\n",
    "      kernel_initializer: Function that creates (random) initial vectors for\n",
    "          the embedding.\n",
    "    \"\"\"\n",
    "    super().__init__(name=f'Embedding_{vocab_size}_{d_feature}')\n",
    "    self._d_feature = d_feature  # feature dimensionality\n",
    "    self._vocab_size = vocab_size\n",
    "    self._kernel_initializer = kernel_initializer\n",
    "\n",
    "  def forward(self, x):\n",
    "    \"\"\"Returns embedding vectors corresponding to input token IDs.\n",
    "\n",
    "    Args:\n",
    "      x: Tensor of token IDs.\n",
    "\n",
    "    Returns:\n",
    "      Tensor of embedding vectors.\n",
    "    \"\"\"\n",
    "    return jnp.take(self.weights, x, axis=0, mode='clip')\n",
    "\n",
    "  def init_weights_and_state(self, input_signature):\n",
    "    \"\"\"Randomly initializes this layer's weights.\"\"\"\n",
    "    del input_signature\n",
    "    shape_w = (self._vocab_size, self._d_feature)\n",
    "    w = self._kernel_initializer(shape_w, self.rng)\n",
    "    self.weights = w\n",
    "```\n",
    "\n",
    "Layers with trainable weights like `Embedding` need to be initialized with the signature (shape and dtype) of the input, and then can be run by calling them.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "executionInfo": {
     "elapsed": 598,
     "status": "ok",
     "timestamp": 1607149436202,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "4MLSQsIiw9Aw",
    "outputId": "394efc9d-9e3c-4f8c-80c2-ce3b5a935e38",
    "ExecuteTime": {
     "end_time": "2025-04-10T08:32:06.195494Z",
     "start_time": "2025-04-10T08:32:06.180354Z"
    }
   },
   "source": [
    "from trax import layers as tl\n",
    "from trax.utils import shapes\n",
    "\n",
    "# Create an input tensor x.\n",
    "x = np.arange(15)\n",
    "print(f'x = {x}')\n",
    "\n",
    "# Create the embedding layer.\n",
    "embedding = tl.Embedding(vocab_size=20, d_feature=32)\n",
    "embedding.init(trax.utils.shapes.signature(x))\n",
    "\n",
    "# Run the layer -- y = embedding(x).\n",
    "y = embedding(x)\n",
    "print(f'shape of y = {y.shape}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "shape of y = (15, 32)\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MgCPl9ZOyCJw"
   },
   "source": [
    "### Models\n",
    "\n",
    "Models in Trax are built from layers most often using the `Serial` and `Branch` combinators. You can read more about those combinators in the [layers intro](https://trax-ml.readthedocs.io/en/latest/notebooks/layers_intro.html) and\n",
    "see the code for many models in `trax/models/`, e.g., this is how the [Transformer Language Model](https://github.com/google/trax/blob/master/trax/models/transformer.py#L167) is implemented. Below is an example of how to build a sentiment classification model."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "executionInfo": {
     "elapsed": 473,
     "status": "ok",
     "timestamp": 1607149436685,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "WoSz5plIyXOU",
    "outputId": "f94c84c4-3224-4231-8879-4a68f328b89e",
    "ExecuteTime": {
     "end_time": "2025-04-10T08:32:08.929315Z",
     "start_time": "2025-04-10T08:32:08.870385Z"
    }
   },
   "source": [
    "model = tl.Serial(\n",
    "    tl.Embedding(vocab_size=8192, d_feature=256),\n",
    "    tl.Mean(axis=1),  # Average on axis 1 (length of sentence).\n",
    "    tl.Dense(2),  # Classify 2 classes.\n",
    ")\n",
    "\n",
    "# You can print model structure.\n",
    "print(model)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serial[\n",
      "  Embedding_8192_256\n",
      "  Mean\n",
      "  Dense_2\n",
      "]\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FcnIjFLD0Ju1"
   },
   "source": [
    "### Data\n",
    "\n",
    "To train your model, you need data. In Trax, data streams are represented as python iterators, so you can call `next(data_stream)` and get a tuple, e.g., `(inputs, targets)`. Trax allows you to use [TensorFlow Datasets](https://www.tensorflow.org/datasets) easily and you can also get an iterator from your own text file using the standard `open('my_file.txt')`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "executionInfo": {
     "elapsed": 19863,
     "status": "ok",
     "timestamp": 1607149456555,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "pKITF1jR0_Of",
    "outputId": "44a73b25-668d-4f85-9133-ebb0f5edd191",
    "ExecuteTime": {
     "end_time": "2025-04-10T08:32:11.671647Z",
     "start_time": "2025-04-10T08:32:11.210296Z"
    }
   },
   "source": [
    "from trax.data.loader.tf import base as dataset\n",
    "\n",
    "train_stream = dataset.TFDS('imdb_reviews', keys=('text', 'label'), train=True)()\n",
    "eval_stream = dataset.TFDS('imdb_reviews', keys=('text', 'label'), train=False)()\n",
    "print(next(train_stream))  # See one example."
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-10 10:32:11.384175: W tensorflow/core/kernels/data/cache_dataset_ops.cc:913] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(b\"This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie's ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor's like Christopher Walken's good name. I could barely sit through it.\", 0)\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fRGj4Skm1kL4"
   },
   "source": [
    "Using the `trax.data` module you can create input processing pipelines, e.g., to tokenize and shuffle your data. You create data pipelines using `trax.data.Serial` and they are functions that you apply to streams to create processed streams."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "executionInfo": {
     "elapsed": 1746,
     "status": "ok",
     "timestamp": 1607149458319,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "AV5wrgjZ10yU",
    "outputId": "82b8e3bc-7812-4cd3-a669-401fef29f1c0",
    "ExecuteTime": {
     "end_time": "2025-04-10T08:32:16.499220Z",
     "start_time": "2025-04-10T08:32:14.137665Z"
    }
   },
   "source": [
    "from trax.data.preprocessing import inputs as preprocessing\n",
    "from trax.data.encoder import encoder\n",
    "\n",
    "data_pipeline = preprocessing.Serial(\n",
    "    encoder.Tokenize(vocab_file='en_8k.subword', keys=[0]),\n",
    "    preprocessing.Shuffle(),\n",
    "    preprocessing.FilterByLength(max_length=2048, length_keys=[0]),\n",
    "    preprocessing.BucketByLength(boundaries=[32, 128, 512, 2048],\n",
    "                                 batch_sizes=[512, 128, 32, 8, 1],\n",
    "                                 length_keys=[0]),\n",
    "    preprocessing.AddLossWeights()\n",
    ")\n",
    "train_batches_stream = data_pipeline(train_stream)\n",
    "eval_batches_stream = data_pipeline(eval_stream)\n",
    "example_batch = next(train_batches_stream)\n",
    "print(example_batch)\n",
    "#print(f'shapes = {[x.shape for x in example_batch]}')  # Check the shapes."
   ],
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Mixed tensor types not supported. All tensors must be either tf.RaggedTensor, tf.Tensor or np.ndarray.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[38], line 15\u001B[0m\n\u001B[1;32m     13\u001B[0m train_batches_stream \u001B[38;5;241m=\u001B[39m data_pipeline(train_stream)\n\u001B[1;32m     14\u001B[0m eval_batches_stream \u001B[38;5;241m=\u001B[39m data_pipeline(eval_stream)\n\u001B[0;32m---> 15\u001B[0m example_batch \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mtrain_batches_stream\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28mprint\u001B[39m(example_batch)\n\u001B[1;32m     17\u001B[0m \u001B[38;5;66;03m#print(f'shapes = {[x.shape for x in example_batch]}')  # Check the shapes.\u001B[39;00m\n",
      "File \u001B[0;32m/raid/mmironczuk/projects/trax-upgrade/trax/data/preprocessing/inputs.py:1100\u001B[0m, in \u001B[0;36madd_loss_weights\u001B[0;34m(generator, id_to_mask)\u001B[0m\n\u001B[1;32m   1080\u001B[0m \u001B[38;5;129m@debug_data_pipeline\u001B[39m\u001B[38;5;241m.\u001B[39mdebug_pipeline\n\u001B[1;32m   1081\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21madd_loss_weights\u001B[39m(generator, id_to_mask\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m   1082\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Add weights to inputs without weights and masks by id if requested.\u001B[39;00m\n\u001B[1;32m   1083\u001B[0m \n\u001B[1;32m   1084\u001B[0m \u001B[38;5;124;03m    The generator stream is augmented in the following way:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1098\u001B[0m \u001B[38;5;124;03m      Examples from the augmented stream.\u001B[39;00m\n\u001B[1;32m   1099\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 1100\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m example \u001B[38;5;129;01min\u001B[39;00m generator:\n\u001B[1;32m   1101\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(example) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m3\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(example) \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m2\u001B[39m:\n\u001B[1;32m   1102\u001B[0m             \u001B[38;5;28;01massert\u001B[39;00m id_to_mask \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot automatically mask this stream.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "File \u001B[0;32m/raid/mmironczuk/projects/trax-upgrade/trax/data/preprocessing/inputs.py:1073\u001B[0m, in \u001B[0;36mbucket_by_length\u001B[0;34m(generator, length_fn, boundaries, batch_sizes, strict_pad_on_len)\u001B[0m\n\u001B[1;32m   1071\u001B[0m boundary \u001B[38;5;241m=\u001B[39m boundaries[bucket_idx]\n\u001B[1;32m   1072\u001B[0m boundary \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01mif\u001B[39;00m boundary \u001B[38;5;241m==\u001B[39m math\u001B[38;5;241m.\u001B[39minf \u001B[38;5;28;01melse\u001B[39;00m boundary\n\u001B[0;32m-> 1073\u001B[0m padded_batch \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mtuple\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1074\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpad_to_max_dims\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mboundary\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstrict_pad_on_len\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mbatched\u001B[49m\n\u001B[1;32m   1075\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1076\u001B[0m \u001B[38;5;28;01myield\u001B[39;00m padded_batch\n\u001B[1;32m   1077\u001B[0m buckets[bucket_idx] \u001B[38;5;241m=\u001B[39m []\n",
      "File \u001B[0;32m/raid/mmironczuk/projects/trax-upgrade/trax/data/preprocessing/inputs.py:1074\u001B[0m, in \u001B[0;36m<genexpr>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m   1071\u001B[0m boundary \u001B[38;5;241m=\u001B[39m boundaries[bucket_idx]\n\u001B[1;32m   1072\u001B[0m boundary \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01mif\u001B[39;00m boundary \u001B[38;5;241m==\u001B[39m math\u001B[38;5;241m.\u001B[39minf \u001B[38;5;28;01melse\u001B[39;00m boundary\n\u001B[1;32m   1073\u001B[0m padded_batch \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mtuple\u001B[39m(\n\u001B[0;32m-> 1074\u001B[0m     \u001B[43mpad_to_max_dims\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mboundary\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstrict_pad_on_len\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m batched\n\u001B[1;32m   1075\u001B[0m )\n\u001B[1;32m   1076\u001B[0m \u001B[38;5;28;01myield\u001B[39;00m padded_batch\n\u001B[1;32m   1077\u001B[0m buckets[bucket_idx] \u001B[38;5;241m=\u001B[39m []\n",
      "File \u001B[0;32m/raid/mmironczuk/projects/trax-upgrade/trax/data/preprocessing/inputs.py:1034\u001B[0m, in \u001B[0;36mpad_to_max_dims\u001B[0;34m(tensors, boundary, strict_pad_on_len)\u001B[0m\n\u001B[1;32m   1032\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m pad_np_tensors(tensors, boundary, strict_pad_on_len)\n\u001B[1;32m   1033\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1034\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   1035\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMixed tensor types not supported. All tensors must be either tf.RaggedTensor, tf.Tensor or np.ndarray.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1036\u001B[0m     )\n",
      "\u001B[0;31mValueError\u001B[0m: Mixed tensor types not supported. All tensors must be either tf.RaggedTensor, tf.Tensor or np.ndarray."
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l25krioP2twf"
   },
   "source": [
    "### Supervised training\n",
    "\n",
    "When you have the model and the data, use `trax.supervised.training` to define training and eval tasks and create a training loop. The Trax training loop optimizes training and will create TensorBoard logs and model checkpoints for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 43631,
     "status": "ok",
     "timestamp": 1607149504226,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "d6bIKUO-3Cw8",
    "outputId": "038e6ad5-0d2f-442b-ffa1-ed431dc1d2e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step      1: Total number of trainable weights: 2097666\n",
      "Step      1: Ran 1 train steps in 1.15 secs\n",
      "Step      1: train WeightedCategoryCrossEntropy |  0.69192106\n",
      "Step      1: eval  WeightedCategoryCrossEntropy |  0.69349981\n",
      "Step      1: eval      WeightedCategoryAccuracy |  0.50312500\n",
      "\n",
      "Step    500: Ran 499 train steps in 10.62 secs\n",
      "Step    500: train WeightedCategoryCrossEntropy |  0.50712883\n",
      "Step    500: eval  WeightedCategoryCrossEntropy |  0.42969493\n",
      "Step    500: eval      WeightedCategoryAccuracy |  0.81406250\n",
      "\n",
      "Step   1000: Ran 500 train steps in 8.89 secs\n",
      "Step   1000: train WeightedCategoryCrossEntropy |  0.35916388\n",
      "Step   1000: eval  WeightedCategoryCrossEntropy |  0.41775789\n",
      "Step   1000: eval      WeightedCategoryAccuracy |  0.79531250\n",
      "\n",
      "Step   1500: Ran 500 train steps in 9.13 secs\n",
      "Step   1500: train WeightedCategoryCrossEntropy |  0.35241464\n",
      "Step   1500: eval  WeightedCategoryCrossEntropy |  0.35194683\n",
      "Step   1500: eval      WeightedCategoryAccuracy |  0.85117188\n",
      "\n",
      "Step   2000: Ran 500 train steps in 8.54 secs\n",
      "Step   2000: train WeightedCategoryCrossEntropy |  0.29129386\n",
      "Step   2000: eval  WeightedCategoryCrossEntropy |  0.37591279\n",
      "Step   2000: eval      WeightedCategoryAccuracy |  0.84062500\n"
     ]
    }
   ],
   "source": [
    "from trax.supervised import training\n",
    "\n",
    "# Training task.\n",
    "train_task = training.TrainTask(\n",
    "    labeled_data=train_batches_stream,\n",
    "    loss_layer=tl.WeightedCategoryCrossEntropy(),\n",
    "    optimizer=trax.optimizers.Adam(0.01),\n",
    "    n_steps_per_checkpoint=500,\n",
    ")\n",
    "\n",
    "# Evaluaton task.\n",
    "eval_task = training.EvalTask(\n",
    "    labeled_data=eval_batches_stream,\n",
    "    metrics=[tl.WeightedCategoryCrossEntropy(), tl.WeightedCategoryAccuracy()],\n",
    "    n_eval_batches=20  # For less variance in eval numbers.\n",
    ")\n",
    "\n",
    "# Training loop saves checkpoints to output_dir.\n",
    "output_dir = os.path.expanduser('~/output_dir/')\n",
    "!rm -rf {output_dir}\n",
    "training_loop = training.Loop(model,\n",
    "                              train_task,\n",
    "                              eval_tasks=[eval_task],\n",
    "                              output_dir=output_dir)\n",
    "\n",
    "# Run 2000 steps (batches).\n",
    "training_loop.run(2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-aCkIu3x686C"
   },
   "source": [
    "After training the model, run it like any layer to get results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 1683,
     "status": "ok",
     "timestamp": 1607149514303,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "yuPu37Lp7GST",
    "outputId": "fdc4d832-2f1d-4aee-87b5-9c9dc1238503"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example input_str: There are a few aspects to Park's movies, and in particular Wallace & Gromit, that I would say make them so great. The first is subtlety and observation, the flagship of which is the character of Gromit. He doesn't speak, he doesn't make any noise, all he has are his eyes, brow, and body posture, and with these he commands the film. Park manages to give us everything we need from this silent character through his expression. The comedy and the emotion is conveyed through the subtlest of movements and it works superbly well.<br /><br />Watching the movie you have to be aware of the entire screen. Normally you'll be guided to things in the movies, the screen won't be cluttered too much, there won't be many things to take your eyes away from the main clue or action. Park seems to need to look the other way with his movies. He throws extra content at his audience, there's action in the background, to the side of the screen, even off screen, and there's just about always something in the foreground to catch your eye. His movies are about multiple viewing and discovery, they're layered with jokes and ancillary action.<br /><br />Throughout this film there are layers of things happening on screen, jokes in the foreground maybe on a jar label and background shadows that give away action. You can imagine that for Park the movies has always been an event, and the movies he loves are ones which he wants to watch again and again. This is what shows in his movies, and in through his most beloved characters.<br /><br />Then there are the bizarre and wacky inventions which Wallace make, something which is reflected in the storyline and the twists and turns of the plot, everything is bizarre and off the wall, yet it seems so perfectly normal in this world. You can imagine that inside Park is the mind of Wallace.<br /><br />There's also one more thing that make these movies so unique, and that's the modelling and precise hand animation. I must admit I was concerned when I knew Dreamworks was involved in the making of this movie, and I thought that they would bring their computer animation experience to the forefront. What I was scared of was Wallace & Gromit becoming CGI entities, or at the smallest, CGI being used to clean up the feel that the modelling brought to the movie.<br /><br />Not so. You can still see thumbprints and toolmarks on the characters, and far from distracting from the movie, this just adds so much real feeling to it and a feeling of physical depth to the characters and the scene on screen.<br /><br />So what of the movie? Well I must say that the plot twist was something I had thought about well before the film was in the cinema and it came as no surprise, but that did not affect my enjoyment one little bit. Actually watching the twist unfold and the comic timing of the discovery and reactions was everything, and it had me just as sucked in as if it was a thriller, yet all the time I was laughing.<br /><br />Watching the movie was fascinating in various ways. To see the animation completed, how wild the inventions are, how Wallace is going to get into trouble and Gromit get him out, where all the cross references are in the movie, and where all the jokes are! I must admit afterwards talking with my friends I couldn't believe how much I had missed.<br /><br />There's something different in this movie than with the others, there's a new level of adult humour in here, and I don't mean rude jokes (although there are a couple that are just so British you can't help laughing), I mean jokes that simply fly over kids heads but slap adults in the face. The kind you are used to seeing come out of somewhere like Pixar. This just adds even more appeal to the movie.<br /><br />Okay though, let me try and be a bit negative here. I didn't notice the voices in this movie, you know how you usually listen to the actors and see if you can recognise them? Well I was just too wrapped up in the movie to care or to notice who they were...okay, that's not negative. Let me try again. The main plot wasn't as strong and gripping as I'd expected, and I found myself being caught up in the side stories and the characters themselves...again...that's not a bad thing, the film was just so much rich entertainment.<br /><br />I honestly can't think of a bad thing to say about this movie, probably the worst thing I could say is that the title sequence at the end is quite repetitive...until the final title! Really, that's the worst I can say.<br /><br />The story is a lot of fun, well set-up, well written, well executed. There's lot's of fantastic characters in here, not just Wallace & Gromit. There's so much happening on screen, so many references and jokes (check out the dresses of Lady Tottingham), cheese jokes everywhere, jokes for all the family. The characters are superbly absorbing and you'll find that you've taken to them before you realise. There's just so much in this movie for everyone.<br /><br />There's so much I could say and write about, but I know it will quickly turn into a backslapping exercise for Park and Aardman, it would also just turn into a series of \"this bit was really funny\" and \"there's a bit when...\", and what I would rather do is tell you that this is a superb movie, to go see it, and to experience the whole thing for yourselves. I will say though that the bunnies are excellent!<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "Model returned sentiment probabilities: [[0.36765265 2.7904649 ]]\n"
     ]
    }
   ],
   "source": [
    "example_input = next(eval_batches_stream)[0][0]\n",
    "example_input_str = trax.data.detokenize(example_input, vocab_file='en_8k.subword')\n",
    "print(f'example input_str: {example_input_str}')\n",
    "sentiment_log_probs = model(example_input[None, :])  # Add batch dimension.\n",
    "print(f'Model returned sentiment probabilities: {np.exp(sentiment_log_probs)}')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "last_runtime": {
    "build_target": "//learning/deepmind/public/tools/ml_python:ml_notebook",
    "kind": "private"
   },
   "name": "Trax Quick Intro",
   "provenance": [
    {
     "file_id": "trax/intro.ipynb",
     "timestamp": 1595931762204
    },
    {
     "file_id": "1v1GvTkEFjMH_1c-bdS7JzNS70u9RUEHV",
     "timestamp": 1578964243645
    },
    {
     "file_id": "1SplqILjJr_ZqXcIUkNIk0tSbthfhYm07",
     "timestamp": 1572044421118
    },
    {
     "file_id": "intro.ipynb",
     "timestamp": 1571858674399
    },
    {
     "file_id": "1sF8QbqJ19ZU6oy5z4GUTt4lgUCjqO6kt",
     "timestamp": 1569980697572
    },
    {
     "file_id": "1EH76AWQ_pvT4i8ZXfkv-SCV4MrmllEl5",
     "timestamp": 1563927451951
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
