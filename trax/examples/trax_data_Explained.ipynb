{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "trax.data Explained",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMN9H/craeNOTmFImALz3Uk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SauravMaheshkar/trax/blob/SauravMaheshkar-example-1/examples/trax_data_Explained.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NWA5uxOmBVz"
      },
      "source": [
        "#@title\n",
        "# Copyright 2020 Google LLC.\n",
        "\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6IGlnMDLf6M"
      },
      "source": [
        "## Install the Latest Version of Trax\n",
        "!pip install --upgrade trax"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOPgYEe2i7Cg"
      },
      "source": [
        "Notebook Author: [@SauravMaheshkar](https://github.com/SauravMaheshkar)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtMr8yxvM2m3"
      },
      "source": [
        "# Introduction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yD3A2vRGSDwy"
      },
      "source": [
        "import trax"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5VsWct1QjPz"
      },
      "source": [
        "# Serial Fn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEa5pT6FQuta"
      },
      "source": [
        "In Trax, we use combinators to build input pipelines, much like building deep learning models. The `Serial` combinator applies layers serially using function composition and uses stack semantics to manage data. \n",
        "\n",
        "Trax has the following definition for a `Serial` combinator.\n",
        "\n",
        "> ```\n",
        "def Serial(*fns):\n",
        "  def composed_fns(generator=None):\n",
        "    for f in fastmath.tree_flatten(fns):\n",
        "      generator = f(generator)\n",
        "    return generator\n",
        "  return composed_fns\n",
        "  ```\n",
        "\n",
        "The `Serial` function has the following structure:\n",
        "\n",
        "* It takes as **input** arbitrary number of functions\n",
        "* Convert the structure into lists\n",
        "* Iterate through the list and apply the functions Serially\n",
        "\n",
        "---\n",
        "\n",
        "The [`fastmath.tree_flatten()`](https://github.com/google/trax/blob/c38a5b1e4c5cfe13d156b3fc0bfdb83554c8f799/trax/fastmath/numpy.py#L195) function, takes a tree as a input and returns a flattened list. This way we can use various generator functions like Tokenize and Shuffle, and apply them serially by '*iterating*' through the list. \n",
        "\n",
        "Initially, we've defined `generator` to `None`. Thus, in the first iteration we have no input and thus the first step executes the first function in our tree structure. In the next iteration, the `generator` variable is updated to be the output of the next function in the list.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rkCvxscXtvk"
      },
      "source": [
        "# Log Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oodQFyHDYJHF"
      },
      "source": [
        "> ```\n",
        "def Log(n_steps_per_example=1, only_shapes=True):\n",
        "  def log(stream):\n",
        "    counter = 0\n",
        "    for example in stream:\n",
        "      item_to_log = example\n",
        "      if only_shapes:\n",
        "        item_to_log = fastmath.nested_map(shapes.signature, example)\n",
        "      if counter % n_steps_per_example == 0:\n",
        "        logging.info(str(item_to_log))\n",
        "        print(item_to_log)\n",
        "      counter += 1\n",
        "      yield example\n",
        "  return log\n",
        "\n",
        "Every Deep Learning Framework needs to have a logging component for efficient debugging. \n",
        "\n",
        "`trax.data.Log` generator uses the `absl` package for logging. It uses a [`fastmath.nested_map`](https://github.com/google/trax/blob/c38a5b1e4c5cfe13d156b3fc0bfdb83554c8f799/trax/fastmath/numpy.py#L80) function that maps a certain function recursively inside a object. In the case depicted below, the function maps the `shapes.signature` recursively inside the input stream, thus giving us the shapes of the various objects in our stream.\n",
        "\n",
        "--\n",
        "\n",
        "The following two cells show the difference between when we set the `only_shapes` variable to `False`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqZZAYC4YlIt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "outputId": "aa36ceb1-65b1-4c65-83ae-c93d197759b7"
      },
      "source": [
        "data_pipeline = trax.data.Serial(\n",
        "    trax.data.TFDS('imdb_reviews', keys=('text', 'label'), train=True),\n",
        "    trax.data.Tokenize(vocab_dir='gs://trax-ml/vocabs/', vocab_file='en_8k.subword', keys=[0]),\n",
        "    trax.data.Log(only_shapes=False)\n",
        "  )\n",
        "example = data_pipeline()\n",
        "print(next(example))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(array([ 182,   31,   43, 5981,   67, 6322,  243, 3898,   22,    8, 2138,\n",
            "          2,   36,   47,   66,  597,  300,   10,   34, 3986, 2613,   64,\n",
            "       5281, 2367,    2,   46, 1902, 4713, 2942, 3461,    8, 4797,   55,\n",
            "       1466, 1351,  409,    3,  121,  114, 1622, 5622,   66,  124, 4106,\n",
            "         47, 1972,   10,  536,    8, 4533,    2,  124, 1466, 3207,   93,\n",
            "        449,   90,  407, 4860,   76,  114, 3898,   22,   36,    6, 2339,\n",
            "       5160,  275, 2395, 6293,  181,    8,  182, 3898,   22,   25,   43,\n",
            "        402, 4423,  794,  995, 3040, 2420, 2128,    2, 5116,    2,    8,\n",
            "         28,  180, 3166, 3171, 3839,   44,   80,  668,  232,    4, 1743,\n",
            "       3661,  239, 3082, 4076,   80, 2067,  124, 2700,   35, 3854, 1052,\n",
            "        221,    8, 6149, 5481, 4607,   12,  547, 2942,   75, 4445, 3054,\n",
            "         29,    3,    7,  245, 5372, 1135,   75,   14, 3304,    2, 4935,\n",
            "       1197,   39, 5281, 2367,    2,   31, 5032, 2528,  121,   12, 3166,\n",
            "       3171, 5888, 5403,    2, 2305,   93,   10,   12, 3898,   22,   37,\n",
            "         31, 3060, 2558,    2,    5,  345, 2715, 2213,    8,  139,  907,\n",
            "       2133, 1051, 2390,  200,   37,  266,   55, 3898,   44,  461,  114,\n",
            "          3, 4269, 1264,  617,   36,    6,  461, 3986, 2613,   64, 5281,\n",
            "       2367,    2,   36,    6, 2730,  177,    8,  139,  449, 1120,  839,\n",
            "       4198,    2,  340,   71,   21]), 0)\n",
            "(array([ 182,   31,   43, 5981,   67, 6322,  243, 3898,   22,    8, 2138,\n",
            "          2,   36,   47,   66,  597,  300,   10,   34, 3986, 2613,   64,\n",
            "       5281, 2367,    2,   46, 1902, 4713, 2942, 3461,    8, 4797,   55,\n",
            "       1466, 1351,  409,    3,  121,  114, 1622, 5622,   66,  124, 4106,\n",
            "         47, 1972,   10,  536,    8, 4533,    2,  124, 1466, 3207,   93,\n",
            "        449,   90,  407, 4860,   76,  114, 3898,   22,   36,    6, 2339,\n",
            "       5160,  275, 2395, 6293,  181,    8,  182, 3898,   22,   25,   43,\n",
            "        402, 4423,  794,  995, 3040, 2420, 2128,    2, 5116,    2,    8,\n",
            "         28,  180, 3166, 3171, 3839,   44,   80,  668,  232,    4, 1743,\n",
            "       3661,  239, 3082, 4076,   80, 2067,  124, 2700,   35, 3854, 1052,\n",
            "        221,    8, 6149, 5481, 4607,   12,  547, 2942,   75, 4445, 3054,\n",
            "         29,    3,    7,  245, 5372, 1135,   75,   14, 3304,    2, 4935,\n",
            "       1197,   39, 5281, 2367,    2,   31, 5032, 2528,  121,   12, 3166,\n",
            "       3171, 5888, 5403,    2, 2305,   93,   10,   12, 3898,   22,   37,\n",
            "         31, 3060, 2558,    2,    5,  345, 2715, 2213,    8,  139,  907,\n",
            "       2133, 1051, 2390,  200,   37,  266,   55, 3898,   44,  461,  114,\n",
            "          3, 4269, 1264,  617,   36,    6,  461, 3986, 2613,   64, 5281,\n",
            "       2367,    2,   36,    6, 2730,  177,    8,  139,  449, 1120,  839,\n",
            "       4198,    2,  340,   71,   21]), 0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyqL-JMCaGn0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "dfd51b28-159c-41b7-ba2a-39e95b1e3964"
      },
      "source": [
        "data_pipeline = trax.data.Serial(\n",
        "    trax.data.TFDS('imdb_reviews', keys=('text', 'label'), train=True),\n",
        "    trax.data.Tokenize(vocab_dir='gs://trax-ml/vocabs/', vocab_file='en_8k.subword', keys=[0]),\n",
        "    trax.data.Log(only_shapes=True)\n",
        "  )\n",
        "example = data_pipeline()\n",
        "print(next(example))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(ShapeDtype{shape:(203,), dtype:int64}, ShapeDtype{shape:(), dtype:int64})\n",
            "(array([ 182,   31,   43, 5981,   67, 6322,  243, 3898,   22,    8, 2138,\n",
            "          2,   36,   47,   66,  597,  300,   10,   34, 3986, 2613,   64,\n",
            "       5281, 2367,    2,   46, 1902, 4713, 2942, 3461,    8, 4797,   55,\n",
            "       1466, 1351,  409,    3,  121,  114, 1622, 5622,   66,  124, 4106,\n",
            "         47, 1972,   10,  536,    8, 4533,    2,  124, 1466, 3207,   93,\n",
            "        449,   90,  407, 4860,   76,  114, 3898,   22,   36,    6, 2339,\n",
            "       5160,  275, 2395, 6293,  181,    8,  182, 3898,   22,   25,   43,\n",
            "        402, 4423,  794,  995, 3040, 2420, 2128,    2, 5116,    2,    8,\n",
            "         28,  180, 3166, 3171, 3839,   44,   80,  668,  232,    4, 1743,\n",
            "       3661,  239, 3082, 4076,   80, 2067,  124, 2700,   35, 3854, 1052,\n",
            "        221,    8, 6149, 5481, 4607,   12,  547, 2942,   75, 4445, 3054,\n",
            "         29,    3,    7,  245, 5372, 1135,   75,   14, 3304,    2, 4935,\n",
            "       1197,   39, 5281, 2367,    2,   31, 5032, 2528,  121,   12, 3166,\n",
            "       3171, 5888, 5403,    2, 2305,   93,   10,   12, 3898,   22,   37,\n",
            "         31, 3060, 2558,    2,    5,  345, 2715, 2213,    8,  139,  907,\n",
            "       2133, 1051, 2390,  200,   37,  266,   55, 3898,   44,  461,  114,\n",
            "          3, 4269, 1264,  617,   36,    6,  461, 3986, 2613,   64, 5281,\n",
            "       2367,    2,   36,    6, 2730,  177,    8,  139,  449, 1120,  839,\n",
            "       4198,    2,  340,   71,   21]), 0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wy8L-e9qcRY4"
      },
      "source": [
        "# Shuffling our datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cfg48KgcrlM"
      },
      "source": [
        "Trax offers two generator functions to add shuffle functionality in our input pipelines. \n",
        "\n",
        "1. The `shuffle` function shuffles a given stream\n",
        "2. The `Shuffle` function returns a shuffle function instead"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iD21oiycWf4"
      },
      "source": [
        "## `shuffle`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVgN1yYAcaKM"
      },
      "source": [
        "> ```\n",
        "def shuffle(samples, queue_size):\n",
        "  if queue_size < 1:\n",
        "    raise ValueError(f'Arg queue_size ({queue_size}) is less than 1.')\n",
        "  if queue_size == 1:\n",
        "    logging.warning('Queue size of 1 results in no shuffling.')\n",
        "  queue = []\n",
        "  try:\n",
        "      queue.append(next(samples))\n",
        "      i = np.random.randint(queue_size)\n",
        "      yield queue[i]\n",
        "      queue[i] = sample\n",
        "  except StopIteration:\n",
        "    logging.warning(\n",
        "        'Not enough samples (%d) to fill initial queue (size %d).',\n",
        "        len(queue), queue_size)\n",
        "  np.random.shuffle(queue)\n",
        "  for sample in queue:\n",
        "    yield sample\n",
        "\n",
        "\n",
        "The `shuffle` function takes two inputs, the data stream and the queue size (minimum number of samples within which the shuffling takes place). Apart from the usual warnings, for negative and unity queue sizes, this generator function shuffles the given stream using [`np.random.randint()`](https://docs.python.org/3/library/random.html#random.randint) by randomly picks out integers using the `queue_size` as a range and then shuffle this new stream again using the [`np.random.shuffle()`](https://docs.python.org/3/library/random.html#random.shuffle)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kdz2fNIfn2l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "110aa969-dab0-4e7a-e75f-41a6ab2fe0c4"
      },
      "source": [
        "sentence = ['Sed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo. Nemo enim ipsam voluptatem quia voluptas sit aspernatur aut odit aut fugit, sed quia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt. Neque porro quisquam est, qui dolorem ipsum quia dolor sit amet, consectetur, adipisci velit, sed quia non numquam eius modi tempora incidunt ut labore et dolore magnam aliquam quaerat voluptatem. Ut enim ad minima veniam, quis nostrum exercitationem ullam corporis suscipit laboriosam, nisi ut aliquid ex ea commodi consequatur? Quis autem vel eum iure reprehenderit qui in ea voluptate velit esse quam nihil molestiae consequatur, vel illum qui dolorem eum fugiat quo voluptas nulla pariatur?',\n",
        "            'But I must explain to you how all this mistaken idea of denouncing pleasure and praising pain was born and I will give you a complete account of the system, and expound the actual teachings of the great explorer of the truth, the master-builder of human happiness. No one rejects, dislikes, or avoids pleasure itself, because it is pleasure, but because those who do not know how to pursue pleasure rationally encounter consequences that are extremely painful. Nor again is there anyone who loves or pursues or desires to obtain pain of itself, because it is pain, but because occasionally circumstances occur in which toil and pain can procure him some great pleasure. To take a trivial example, which of us ever undertakes laborious physical exercise, except to obtain some advantage from it? But who has any right to find fault with a man who chooses to enjoy a pleasure that has no annoying consequences, or one who avoids a pain that produces no resultant pleasure?',\n",
        "            'Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum',\n",
        "            'At vero eos et accusamus et iusto odio dignissimos ducimus qui blanditiis praesentium voluptatum deleniti atque corrupti quos dolores et quas molestias excepturi sint occaecati cupiditate non provident, similique sunt in culpa qui officia deserunt mollitia animi, id est laborum et dolorum fuga. Et harum quidem rerum facilis est et expedita distinctio. Nam libero tempore, cum soluta nobis est eligendi optio cumque nihil impedit quo minus id quod maxime placeat facere possimus, omnis voluptas assumenda est, omnis dolor repellendus. Temporibus autem quibusdam et aut officiis debitis aut rerum necessitatibus saepe eveniet ut et voluptates repudiandae sint et molestiae non recusandae. Itaque earum rerum hic tenetur a sapiente delectus, ut aut reiciendis voluptatibus maiores alias consequatur aut perferendis doloribus asperiores repellat.']\n",
        "\n",
        "def sample_generator(x):\n",
        "  for i in x:\n",
        "    yield i\n",
        "\n",
        "example_shuffle = list(trax.data.inputs.shuffle(sample_generator(sentence), queue_size = 2))\n",
        "example_shuffle"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Sed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo. Nemo enim ipsam voluptatem quia voluptas sit aspernatur aut odit aut fugit, sed quia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt. Neque porro quisquam est, qui dolorem ipsum quia dolor sit amet, consectetur, adipisci velit, sed quia non numquam eius modi tempora incidunt ut labore et dolore magnam aliquam quaerat voluptatem. Ut enim ad minima veniam, quis nostrum exercitationem ullam corporis suscipit laboriosam, nisi ut aliquid ex ea commodi consequatur? Quis autem vel eum iure reprehenderit qui in ea voluptate velit esse quam nihil molestiae consequatur, vel illum qui dolorem eum fugiat quo voluptas nulla pariatur?',\n",
              " 'Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum',\n",
              " 'But I must explain to you how all this mistaken idea of denouncing pleasure and praising pain was born and I will give you a complete account of the system, and expound the actual teachings of the great explorer of the truth, the master-builder of human happiness. No one rejects, dislikes, or avoids pleasure itself, because it is pleasure, but because those who do not know how to pursue pleasure rationally encounter consequences that are extremely painful. Nor again is there anyone who loves or pursues or desires to obtain pain of itself, because it is pain, but because occasionally circumstances occur in which toil and pain can procure him some great pleasure. To take a trivial example, which of us ever undertakes laborious physical exercise, except to obtain some advantage from it? But who has any right to find fault with a man who chooses to enjoy a pleasure that has no annoying consequences, or one who avoids a pain that produces no resultant pleasure?',\n",
              " 'At vero eos et accusamus et iusto odio dignissimos ducimus qui blanditiis praesentium voluptatum deleniti atque corrupti quos dolores et quas molestias excepturi sint occaecati cupiditate non provident, similique sunt in culpa qui officia deserunt mollitia animi, id est laborum et dolorum fuga. Et harum quidem rerum facilis est et expedita distinctio. Nam libero tempore, cum soluta nobis est eligendi optio cumque nihil impedit quo minus id quod maxime placeat facere possimus, omnis voluptas assumenda est, omnis dolor repellendus. Temporibus autem quibusdam et aut officiis debitis aut rerum necessitatibus saepe eveniet ut et voluptates repudiandae sint et molestiae non recusandae. Itaque earum rerum hic tenetur a sapiente delectus, ut aut reiciendis voluptatibus maiores alias consequatur aut perferendis doloribus asperiores repellat.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-kTDkF-e7Vn"
      },
      "source": [
        "## `Shuffle`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5Djvqw2e9Jg"
      },
      "source": [
        "> ```\n",
        "def Shuffle(queue_size=1024): \n",
        "  return lambda g: shuffle(g, queue_size)\n",
        "\n",
        "This function returns the aforementioned `shuffle` function and is mostly used in input pipelines.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AA-Z4Sipkq98"
      },
      "source": [
        "# Batch Generators"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzwONDulksbd"
      },
      "source": [
        "## `batch`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DCABkndkudF"
      },
      "source": [
        "This function, creates batches for the input generator function.\n",
        "\n",
        "> ```\n",
        "def batch(generator, batch_size):\n",
        "  if batch_size <= 0:\n",
        "    raise ValueError(f'Batch size must be positive, but is {batch_size}.')\n",
        "  buf = []\n",
        "  for example in generator:\n",
        "    buf.append(example)  \n",
        "    if len(buf) == batch_size:\n",
        "      batched_example = tuple(np.stack(x) for x in zip(*buf))\n",
        "      yield batched_example\n",
        "      buf = []\n",
        "\n",
        "It keeps adding objects from the generator into a list until the size becomes equal to the `batch_size` and then creates batches using the `np.stack()` function.\n",
        "\n",
        "It also raises an error for non-positive batch_sizes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZMKY6VUpD3M"
      },
      "source": [
        "## `Batch`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6pYJHgOpIG4"
      },
      "source": [
        "> ```\n",
        "    def Batch(batch_size):  \n",
        "      return lambda g: batch(g, batch_size)\n",
        "\n",
        "This Function returns the aforementioned `batch` function with given batch size."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmQzaXw9vrbW"
      },
      "source": [
        "# Pad to Maximum Dimensions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iL3MuKQIvt-Q"
      },
      "source": [
        "This function is used to pad a tuple of tensors to a joint dimension and return their batch.\n",
        "\n",
        "For example, in this case a pair of tensors (1,2) and ( (3,4) , (5,6) ) is changed to (1,2,0) and ( (3,4) , (5,6) , 0)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvbBDuq4p4qW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ed69c541-3219-4a23-cf73-4568e3e2882f"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "tensors = np.array([(1.,2.),\n",
        "           ((3.,4.),(5.,6.))])\n",
        "padded_tensors = trax.data.inputs.pad_to_max_dims(tensors=tensors, boundary=3)\n",
        "padded_tensors"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.0, 2.0, 0],\n",
              "       [(3.0, 4.0), (5.0, 6.0), 0]], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDQQYCdLOkl1"
      },
      "source": [
        "# Creating Buckets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjGD3YKJWj58"
      },
      "source": [
        "For training Recurrent Neural Networks, with large vocabulary a method called Bucketing is usually applied. \n",
        "\n",
        "The usual technique of using padding ensures that all occurences within a mini-batch are of the same length. But this reduces the inter-batch variability and intuitively puts similar sentences into the same batch therefore, reducing the overall robustness of the system. \n",
        "\n",
        "Thus, we use Bucketing where multiple buckets are created depending on the length of the sentences and these occurences are assigned to buckets on the basis of which bucket corresponds to it's length. We need to ensure that the bucket sizes are large for adding some variablity to the system."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17z3ASA-OrSF"
      },
      "source": [
        "## `bucket_by_length`\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rf5trhANYpy5"
      },
      "source": [
        "> ```\n",
        "def bucket_by_length(generator, length_fn, boundaries, batch_sizes,strict_pad_on_len=False):\n",
        "  buckets = [[] for _ in range(len(batch_sizes))]\n",
        "  boundaries = boundaries + [math.inf] \n",
        "  for example in generator:\n",
        "    length = length_fn(example)\n",
        "    bucket_idx = min([i for i, b in enumerate(boundaries) if length <= b])\n",
        "    buckets[bucket_idx].append(example)\n",
        "    if len(buckets[bucket_idx]) == batch_sizes[bucket_idx]:\n",
        "      batched = zip(*buckets[bucket_idx])\n",
        "      boundary = boundaries[bucket_idx]\n",
        "      boundary = None if boundary == math.inf else boundary\n",
        "      padded_batch = tuple(\n",
        "          pad_to_max_dims(x, boundary, strict_pad_on_len) for x in batched)\n",
        "      yield padded_batch\n",
        "      buckets[bucket_idx] = []\n",
        "\n",
        "---\n",
        "\n",
        "This function can be summarised as:\n",
        "\n",
        "* Create buckets as per the lengths given in the `batch_sizes` array\n",
        "\n",
        "* Assign sentences into buckets if their length matches the bucket size\n",
        "\n",
        "* If padding is required, we use the `pad_to_max_dims` function\n",
        "\n",
        "---\n",
        "\n",
        "### Parameters\n",
        "\n",
        "1. **generator:** The input generator function\n",
        "2. **length_fn:** A custom length function for determing the length of functions, not necessarily `len()`\n",
        "3. **boundaries:** A python list containing corresponding bucket boundaries\n",
        "4. **batch_sizes:** A python list containing batch sizes\n",
        "5. **strict_pad_on_len:** â€“ A python boolean variable (`True` or `False`). If set to true then the function pads on the length dimension, where dim[0] is strictly a multiple of boundary.\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0uQZaaPVyF_"
      },
      "source": [
        "## `BucketByLength`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qhh21q71aX3l"
      },
      "source": [
        "> ```\n",
        "def BucketByLength(boundaries, batch_sizes,length_keys=None, length_axis=0, strict_pad_on_len=False):\n",
        "  length_keys = length_keys or [0, 1]\n",
        "  length_fn = lambda x: _length_fn(x, length_axis, length_keys)\n",
        "  return lambda g: bucket_by_length(g, length_fn, boundaries, batch_sizes, strict_pad_on_len)\n",
        "\n",
        "---\n",
        "\n",
        "This function, is usually used inside input pipelines(*combinators*) and uses the afforementioned `bucket_by_length`. It applies a predefined `length_fn` which chooses the maximum shape on length_axis over length_keys.\n",
        "\n",
        "It's use is illustrated below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFeqDQNsV0PV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "ab9139c1-de56-4570-bcb6-731c1b475b12"
      },
      "source": [
        "data_pipeline = trax.data.Serial(\n",
        "    trax.data.TFDS('imdb_reviews', keys=('text', 'label'), train=True),\n",
        "    trax.data.Tokenize(vocab_dir='gs://trax-ml/vocabs/', vocab_file='en_8k.subword', keys=[0]),\n",
        "    trax.data.BucketByLength(boundaries=[32, 128, 512, 2048],\n",
        "                             batch_sizes=[512, 128,  32,    8, 1],\n",
        "                             length_keys=[0]),\n",
        "    trax.data.Log(only_shapes=True)\n",
        "  )\n",
        "example = data_pipeline()\n",
        "print(next(example))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(ShapeDtype{shape:(8, 2048), dtype:int64}, ShapeDtype{shape:(8,), dtype:int64})\n",
            "(array([[ 155,  452,   29, ...,    0,    0,    0],\n",
            "       [ 182, 1989, 1826, ...,    0,    0,    0],\n",
            "       [1389, 2597, 5378, ...,    0,    0,    0],\n",
            "       ...,\n",
            "       [4846, 1008,    2, ...,    0,    0,    0],\n",
            "       [  68,   12,  173, ...,    0,    0,    0],\n",
            "       [ 186, 3817, 2064, ...,    0,    0,    0]]), array([0, 1, 1, 1, 1, 0, 1, 0]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9D0YdAT_ceSN"
      },
      "source": [
        "# Filter by Length"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLvi4Wu-eFAF"
      },
      "source": [
        "> ```\n",
        "def FilterByLength(max_length,length_keys=None, length_axis=0):\n",
        "  length_keys = length_keys or [0, 1]\n",
        "  length_fn = lambda x: _length_fn(x, length_axis, length_keys)\n",
        "  def filtered(gen):\n",
        "    for example in gen:\n",
        "      if length_fn(example) <= max_length:\n",
        "        yield example\n",
        "  return filtered\n",
        "\n",
        "---\n",
        "\n",
        "This function used the same predefined `length_fn` to only include those instances which are less than the given `max_length` parameter.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qyueQ1z-cg2p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "da007ab0-e719-4044-e6a4-6bba5f43131e"
      },
      "source": [
        "Filtered = trax.data.Serial(\n",
        "    trax.data.TFDS('imdb_reviews', keys=('text', 'label'), train=True),\n",
        "    trax.data.Tokenize(vocab_dir='gs://trax-ml/vocabs/', vocab_file='en_8k.subword', keys=[0]),\n",
        "    trax.data.BucketByLength(boundaries=[32, 128, 512, 2048],\n",
        "                             batch_sizes=[512, 128,  32,    8, 1],\n",
        "                             length_keys=[0]),\n",
        "    trax.data.FilterByLength(max_length=2048, length_keys=[0]),\n",
        "    trax.data.Log(only_shapes=True)\n",
        "  )\n",
        "filtered_example = Filtered()\n",
        "print(next(filtered_example))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(ShapeDtype{shape:(8, 2048), dtype:int64}, ShapeDtype{shape:(8,), dtype:int64})\n",
            "(array([[ 155,  452,   29, ...,    0,    0,    0],\n",
            "       [ 182, 1989, 1826, ...,    0,    0,    0],\n",
            "       [1389, 2597, 5378, ...,    0,    0,    0],\n",
            "       ...,\n",
            "       [4846, 1008,    2, ...,    0,    0,    0],\n",
            "       [  68,   12,  173, ...,    0,    0,    0],\n",
            "       [ 186, 3817, 2064, ...,    0,    0,    0]]), array([0, 1, 1, 1, 1, 0, 1, 0]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XRrJSsUeZX-"
      },
      "source": [
        "# Adding Loss Weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3ySYhnpejy4"
      },
      "source": [
        "## `add_loss_weights`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgaXAlhgeuQv"
      },
      "source": [
        "> ```\n",
        "def add_loss_weights(generator, id_to_mask=None):\n",
        "  for example in generator:\n",
        "    if len(example) > 3 or len(example) < 2:\n",
        "      assert id_to_mask is None, 'Cannot automatically mask this stream.'\n",
        "      yield example\n",
        "    else:\n",
        "      if len(example) == 2:\n",
        "        weights = np.ones_like(example[1]).astype(np.float32)\n",
        "      else:\n",
        "        weights = example[2].astype(np.float32)\n",
        "      mask = 1.0 - np.equal(example[1], id_to_mask).astype(np.float32)\n",
        "      weights *= mask\n",
        "      yield (example[0], example[1], weights)\n",
        "\n",
        "---\n",
        "\n",
        "This function essentially adds a loss mask (tensor of ones of the same shape) to the input stream. \n",
        "\n",
        "**Masking** is essentially a way to tell sequence-processing layers that certain timesteps in an input are missing, and thus should be skipped when processing the data.\n",
        "\n",
        "Thus, it adds 'weights' to the system. \n",
        "\n",
        "---\n",
        "\n",
        "### Parameters\n",
        "\n",
        "1. **generator:** The input data generator\n",
        "2. **id_to_mask:** The value with which to mask. Can be used as `<PAD>` in NLP."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZPWc6a9hk_u"
      },
      "source": [
        "```\n",
        "\n",
        "train_generator = trax.data.inputs.add_loss_weights(\n",
        "    data_generator(batch_size, x_train, y_train,vocab['<PAD>'], True),\n",
        "    id_to_mask=vocab['<PAD>'])\n",
        "\n",
        "\n",
        "```\n",
        "\n",
        "For example, in this case I used the `add_loss_weights` function to add padding while implementing Named Entity Recogntion using the Reformer Architecture. You can read more about the project [here](https://www.kaggle.com/sauravmaheshkar/trax-ner-using-reformer)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GL31NErOgL3u"
      },
      "source": [
        "## `AddLossWeights`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBLf6iuXgPp2"
      },
      "source": [
        "This function performs the afforementioned `add_loss_weights` to the data stream. \n",
        "\n",
        "> ```\n",
        "def AddLossWeights(id_to_mask=None):\n",
        "  return lambda g: add_loss_weights(g,id_to_mask=id_to_mask)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jwtt-k_2iHEy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "52295b0e-ff9c-415e-9ba6-1d5c1359b508"
      },
      "source": [
        "data_pipeline = trax.data.Serial(\n",
        "    trax.data.TFDS('imdb_reviews', keys=('text', 'label'), train=True),\n",
        "    trax.data.Tokenize(vocab_dir='gs://trax-ml/vocabs/', vocab_file='en_8k.subword', keys=[0]),\n",
        "    trax.data.Shuffle(),\n",
        "    trax.data.FilterByLength(max_length=2048, length_keys=[0]),\n",
        "    trax.data.BucketByLength(boundaries=[  32, 128, 512, 2048],\n",
        "                             batch_sizes=[512, 128,  32,    8, 1],\n",
        "                             length_keys=[0]),\n",
        "    trax.data.AddLossWeights(),\n",
        "    trax.data.Log(only_shapes=True)\n",
        "  )\n",
        "\n",
        "example = data_pipeline()\n",
        "print(next(example))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(ShapeDtype{shape:(8, 2048), dtype:int64}, ShapeDtype{shape:(8,), dtype:int64}, ShapeDtype{shape:(8,), dtype:float32})\n",
            "(array([[4176,  570,  636, ...,    0,    0,    0],\n",
            "       [3030,    2,    7, ...,    0,    0,    0],\n",
            "       [  28, 3898,   22, ...,    0,    0,    0],\n",
            "       ...,\n",
            "       [ 139,   36,   76, ...,    0,    0,    0],\n",
            "       [2275,    2, 4198, ...,    0,    0,    0],\n",
            "       [ 182,  103,  151, ...,    0,    0,    0]]), array([0, 1, 1, 0, 0, 0, 1, 0]), array([1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32))\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}