{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 436,
     "status": "ok",
     "timestamp": 1607381103381,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "1ecEWLK0nsyg"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "# Copyright 2020 Google LLC.\n",
    "\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "executionInfo": {
     "elapsed": 447,
     "status": "ok",
     "timestamp": 1607381103836,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "vxLvhYV5XrvS",
    "outputId": "f399419a-f30c-462d-b66e-61fa55c1a466",
    "ExecuteTime": {
     "end_time": "2025-04-09T13:39:16.580159Z",
     "start_time": "2025-04-09T13:39:16.567553Z"
    }
   },
   "source": [
    "#!pip install -q -U trax\n",
    "import sys\n",
    "\n",
    "# For example, if trax is inside a 'src' directory\n",
    "project_root = '/raid/mmironczuk/projects/trax-upgrade'\n",
    "sys.path.insert(0, project_root)\n",
    "\n",
    "# Option to verify the import path\n",
    "print(f\"Python will look for packages in: {sys.path[0]}\")\n",
    "\n",
    "# Import trax\n",
    "import trax\n",
    "\n",
    "# Verify the source of the imported package\n",
    "print(f\"Imported trax from: {trax.__file__}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python will look for packages in: /raid/mmironczuk/projects/trax-upgrade\n",
      "Imported trax from: /raid/mmironczuk/projects/trax-upgrade/trax/__init__.py\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "executionInfo": {
     "elapsed": 34658,
     "status": "ok",
     "timestamp": 1607381138504,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "ssFKSDd3X9Xj",
    "outputId": "9eba95c4-ba52-461f-ea42-6a7b1d671a3f",
    "ExecuteTime": {
     "end_time": "2025-04-09T13:39:26.681738Z",
     "start_time": "2025-04-09T13:39:21.517334Z"
    }
   },
   "source": [
    "from trax import fastmath\n",
    "\n",
    "# Use the tensorflow-numpy backend.\n",
    "fastmath.set_backend(fastmath.Backend.JAX.value)\n",
    "print(trax.fastmath.backend_name())\n",
    "print(fastmath.jax.jax.devices())"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-09 15:39:22.117015: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-04-09 15:39:22.145157: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-04-09 15:39:22.153895: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-09 15:39:22.173411: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-09 15:39:23.617740: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "executionInfo": {
     "elapsed": 18987,
     "status": "ok",
     "timestamp": 1607381157508,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "OHKt1_SaYGZW",
    "ExecuteTime": {
     "end_time": "2025-04-09T13:41:21.627627Z",
     "start_time": "2025-04-09T13:40:38.954264Z"
    }
   },
   "source": [
    "# https://www.tensorflow.org/datasets/catalog/fashion_mnist\n",
    "from trax.data.preprocessing import inputs as preprocessing\n",
    "from trax.data.loader.tf import base as dataset\n",
    "\n",
    "train_stream = dataset.TFDS('fashion_mnist', keys=('image', 'label'), train=True)()\n",
    "eval_stream = dataset.TFDS('fashion_mnist', keys=('image', 'label'), train=False)()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-09 15:40:40.139994: W external/local_tsl/tsl/platform/cloud/google_auth_provider.cc:184] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"NOT_FOUND: Could not locate the credentials file.\". Retrieving token from GCE failed with \"FAILED_PRECONDITION: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Could not resolve host: metadata.google.internal\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1mDownloading and preparing dataset 29.45 MiB (download: 29.45 MiB, generated: 36.42 MiB, total: 65.87 MiB) to /root/tensorflow_datasets/fashion_mnist/3.0.1...\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dl Completed...: 0 url [00:00, ? url/s]\n",
      "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001B[A\n",
      "\n",
      "Dl Completed...:   0%|          | 0/1 [00:00<?, ? url/s]\n",
      "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001B[A\n",
      "\n",
      "Dl Completed...:   0%|          | 0/2 [00:00<?, ? url/s]\n",
      "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001B[A\n",
      "\n",
      "Dl Completed...:   0%|          | 0/3 [00:00<?, ? url/s]\n",
      "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001B[A\n",
      "\n",
      "Dl Completed...:   0%|          | 0/4 [00:00<?, ? url/s]\n",
      "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001B[A\n",
      "\n",
      "Dl Completed...:   0%|          | 0/4 [00:00<?, ? url/s]\n",
      "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001B[A\n",
      "\n",
      "Dl Completed...:   0%|          | 0/4 [00:00<?, ? url/s]\n",
      "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001B[A\n",
      "\n",
      "Dl Completed...:   0%|          | 0/4 [00:00<?, ? url/s]\n",
      "Dl Size...:   0%|          | 0/4 [00:00<?, ? MiB/s]\u001B[A\n",
      "\n",
      "Dl Completed...:  25%|██▌       | 1/4 [00:00<00:00,  3.83 url/s]\n",
      "Dl Size...:   0%|          | 0/4 [00:00<?, ? MiB/s]\u001B[A\n",
      "\n",
      "Dl Completed...:  25%|██▌       | 1/4 [00:00<00:00,  3.83 url/s]\n",
      "Dl Size...:   0%|          | 0/29 [00:00<?, ? MiB/s]\u001B[A\n",
      "\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:00<00:00,  3.83 url/s]\n",
      "Dl Size...:   0%|          | 0/29 [00:00<?, ? MiB/s]\u001B[A\n",
      "\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:00<00:00,  3.83 url/s]\n",
      "Dl Size...:   0%|          | 0/29 [00:00<?, ? MiB/s]\u001B[A\n",
      "\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:00<00:00,  3.83 url/s]]\u001B[A\u001B[A\n",
      "Dl Size...:   0%|          | 0/29 [00:00<?, ? MiB/s]\u001B[A\n",
      "\n",
      "Extraction completed...:   0%|          | 0/2 [00:00<?, ? file/s]\u001B[A\u001B[A\n",
      "\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:00<00:00,  3.83 url/s]2 file/s]\u001B[A\u001B[A\n",
      "Dl Size...:   0%|          | 0/29 [00:00<?, ? MiB/s]\u001B[A\n",
      "\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:00<00:00,  3.83 url/s]2 file/s]\u001B[A\u001B[A\n",
      "Dl Size...:   0%|          | 0/29 [00:00<?, ? MiB/s]\u001B[A\n",
      "\n",
      "Extraction completed...: 100%|██████████| 2/2 [00:00<00:00,  2.82 file/s]\u001B[A\u001B[A\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:00<00:00,  3.83 url/s]\n",
      "Dl Size...:   3%|▎         | 1/29 [00:00<00:12,  2.23 MiB/s]\u001B[A\n",
      "\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:00<00:00,  3.83 url/s]2 file/s]\u001B[A\u001B[A\n",
      "Dl Size...:   7%|▋         | 2/29 [00:00<00:12,  2.23 MiB/s]\u001B[A\n",
      "\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:00<00:00,  3.83 url/s]2 file/s]\u001B[A\u001B[A\n",
      "Dl Size...:  10%|█         | 3/29 [00:00<00:11,  2.23 MiB/s]\u001B[A\n",
      "\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:00<00:00,  3.83 url/s]2 file/s]\u001B[A\u001B[A\n",
      "Dl Size...:  14%|█▍        | 4/29 [00:00<00:11,  2.23 MiB/s]\u001B[A\n",
      "\n",
      "Extraction completed...: 100%|██████████| 2/2 [00:00<00:00,  2.82 file/s]\u001B[A\u001B[A\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:00<00:00,  3.83 url/s]\n",
      "Dl Size...:  17%|█▋        | 5/29 [00:00<00:02, 11.22 MiB/s]\u001B[A\n",
      "\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:00<00:00,  3.83 url/s]2 file/s]\u001B[A\u001B[A\n",
      "Dl Size...:  21%|██        | 6/29 [00:00<00:02, 11.22 MiB/s]\u001B[A\n",
      "\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:00<00:00,  3.83 url/s]2 file/s]\u001B[A\u001B[A\n",
      "Dl Size...:  24%|██▍       | 7/29 [00:00<00:01, 11.22 MiB/s]\u001B[A\n",
      "\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:00<00:00,  3.83 url/s]2 file/s]\u001B[A\u001B[A\n",
      "Dl Size...:  28%|██▊       | 8/29 [00:00<00:01, 11.22 MiB/s]\u001B[A\n",
      "\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:00<00:00,  4.76 url/s]2 file/s]\u001B[A\u001B[A\n",
      "Dl Size...:  28%|██▊       | 8/29 [00:00<00:01, 11.22 MiB/s]\u001B[A\n",
      "\n",
      "Extraction completed...: 100%|██████████| 2/2 [00:00<00:00,  2.82 file/s]\u001B[A\u001B[A\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:00<00:00,  4.76 url/s]\n",
      "Dl Size...:  31%|███       | 9/29 [00:00<00:01, 18.01 MiB/s]\u001B[A\n",
      "\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:00<00:00,  4.76 url/s]2 file/s]\u001B[A\u001B[A\n",
      "Dl Size...:  34%|███▍      | 10/29 [00:00<00:01, 18.01 MiB/s]\u001B[A\n",
      "\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:00<00:00,  4.76 url/s]2 file/s]\u001B[A\u001B[A\n",
      "Dl Size...:  38%|███▊      | 11/29 [00:00<00:00, 18.01 MiB/s]\u001B[A\n",
      "\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:00<00:00,  4.76 url/s]2 file/s]\u001B[A\u001B[A\n",
      "Dl Size...:  41%|████▏     | 12/29 [00:00<00:00, 18.01 MiB/s]\u001B[A\n",
      "\n",
      "Extraction completed...: 100%|██████████| 2/2 [00:00<00:00,  2.82 file/s]\u001B[A\u001B[A\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:00<00:00,  4.76 url/s]\n",
      "Dl Size...:  45%|████▍     | 13/29 [00:00<00:00, 22.06 MiB/s]\u001B[A\n",
      "\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:00<00:00,  4.76 url/s]2 file/s]\u001B[A\u001B[A\n",
      "Dl Size...:  48%|████▊     | 14/29 [00:00<00:00, 22.06 MiB/s]\u001B[A\n",
      "\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:00<00:00,  4.76 url/s]2 file/s]\u001B[A\u001B[A\n",
      "Dl Size...:  52%|█████▏    | 15/29 [00:00<00:00, 22.06 MiB/s]\u001B[A\n",
      "\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:00<00:00,  4.76 url/s]2 file/s]\u001B[A\u001B[A\n",
      "Dl Size...:  52%|█████▏    | 15/29 [00:00<00:00, 22.06 MiB/s]\u001B[A\n",
      "\n",
      "Extraction completed...:  67%|██████▋   | 2/3 [00:00<00:00,  2.82 file/s]\u001B[A\u001B[A\n",
      "\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:00<00:00,  4.76 url/s]9 file/s]\u001B[A\u001B[A\n",
      "Dl Size...:  52%|█████▏    | 15/29 [00:00<00:00, 22.06 MiB/s]\u001B[A\n",
      "\n",
      "Extraction completed...: 100%|██████████| 3/3 [00:00<00:00,  3.39 file/s]\u001B[A\u001B[A\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:00<00:00,  4.76 url/s]\n",
      "Dl Size...:  55%|█████▌    | 16/29 [00:00<00:00, 22.40 MiB/s]\u001B[A\n",
      "\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:00<00:00,  4.76 url/s]9 file/s]\u001B[A\u001B[A\n",
      "Dl Size...:  59%|█████▊    | 17/29 [00:00<00:00, 22.40 MiB/s]\u001B[A\n",
      "\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:00<00:00,  4.76 url/s]9 file/s]\u001B[A\u001B[A\n",
      "Dl Size...:  62%|██████▏   | 18/29 [00:00<00:00, 22.40 MiB/s]\u001B[A\n",
      "\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  4.76 url/s]9 file/s]\u001B[A\u001B[A\n",
      "Dl Size...:  66%|██████▌   | 19/29 [00:01<00:00, 22.40 MiB/s]\u001B[A\n",
      "\n",
      "Extraction completed...: 100%|██████████| 3/3 [00:01<00:00,  3.39 file/s]\u001B[A\u001B[A\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  4.76 url/s]\n",
      "Dl Size...:  69%|██████▉   | 20/29 [00:01<00:00, 25.89 MiB/s]\u001B[A\n",
      "\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  4.76 url/s]9 file/s]\u001B[A\u001B[A\n",
      "Dl Size...:  72%|███████▏  | 21/29 [00:01<00:00, 25.89 MiB/s]\u001B[A\n",
      "\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  4.76 url/s]9 file/s]\u001B[A\u001B[A\n",
      "Dl Size...:  76%|███████▌  | 22/29 [00:01<00:00, 25.89 MiB/s]\u001B[A\n",
      "\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  4.76 url/s]9 file/s]\u001B[A\u001B[A\n",
      "Dl Size...:  79%|███████▉  | 23/29 [00:01<00:00, 25.89 MiB/s]\u001B[A\n",
      "\n",
      "Extraction completed...: 100%|██████████| 3/3 [00:01<00:00,  3.39 file/s]\u001B[A\u001B[A\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  4.76 url/s]\n",
      "Dl Size...:  83%|████████▎ | 24/29 [00:01<00:00, 28.56 MiB/s]\u001B[A\n",
      "\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  4.76 url/s]9 file/s]\u001B[A\u001B[A\n",
      "Dl Size...:  86%|████████▌ | 25/29 [00:01<00:00, 28.56 MiB/s]\u001B[A\n",
      "\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  4.76 url/s]9 file/s]\u001B[A\u001B[A\n",
      "Dl Size...:  90%|████████▉ | 26/29 [00:01<00:00, 28.56 MiB/s]\u001B[A\n",
      "\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  4.76 url/s]9 file/s]\u001B[A\u001B[A\n",
      "Dl Size...:  93%|█████████▎| 27/29 [00:01<00:00, 28.56 MiB/s]\u001B[A\n",
      "\n",
      "Extraction completed...: 100%|██████████| 3/3 [00:01<00:00,  3.39 file/s]\u001B[A\u001B[A\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  4.76 url/s]\n",
      "Dl Size...:  97%|█████████▋| 28/29 [00:01<00:00, 30.79 MiB/s]\u001B[A\n",
      "\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  4.76 url/s]9 file/s]\u001B[A\u001B[A\n",
      "Dl Size...: 100%|██████████| 29/29 [00:01<00:00, 30.79 MiB/s]\u001B[A\n",
      "\n",
      "Dl Completed...: 100%|██████████| 4/4 [00:01<00:00,  2.72 url/s]9 file/s]\u001B[A\u001B[A\n",
      "Dl Size...: 100%|██████████| 29/29 [00:01<00:00, 30.79 MiB/s]\u001B[A\n",
      "\n",
      "Dl Completed...: 100%|██████████| 4/4 [00:01<00:00,  2.72 url/s]9 file/s]\u001B[A\u001B[A\n",
      "Dl Size...: 100%|██████████| 29/29 [00:01<00:00, 30.79 MiB/s]\u001B[A\n",
      "\n",
      "Extraction completed...:  75%|███████▌  | 3/4 [00:01<00:00,  3.39 file/s]\u001B[A\u001B[A\n",
      "\n",
      "Dl Completed...: 100%|██████████| 4/4 [00:01<00:00,  2.72 url/s]1 file/s]\u001B[A\u001B[A\n",
      "Dl Size...: 100%|██████████| 29/29 [00:01<00:00, 30.79 MiB/s]\u001B[A\n",
      "\n",
      "Extraction completed...: 100%|██████████| 4/4 [00:01<00:00,  2.13 file/s]\u001B[A\u001B[A\n",
      "Dl Size...: 100%|██████████| 29/29 [00:01<00:00, 15.39 MiB/s]\n",
      "Dl Completed...: 100%|██████████| 4/4 [00:01<00:00,  2.12 url/s]\n",
      "Generating splits...:   0%|          | 0/2 [00:00<?, ? splits/s]\n",
      "Generating train examples...:   0%|          | 0/60000 [00:00<?, ? examples/s]\u001B[A2025-04-09 15:40:44.707716: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6113 MB memory:  -> device: 0, name: Tesla V100-DGXS-32GB, pci bus id: 0000:0f:00.0, compute capability: 7.0\n",
      "\n",
      "Generating train examples...:   1%|          | 674/60000 [00:01<01:28, 673.71 examples/s]\u001B[A\n",
      "Generating train examples...:   4%|▍         | 2627/60000 [00:02<00:40, 1425.67 examples/s]\u001B[A\n",
      "Generating train examples...:   8%|▊         | 4578/60000 [00:03<00:33, 1665.42 examples/s]\u001B[A\n",
      "Generating train examples...:  11%|█         | 6528/60000 [00:04<00:30, 1777.54 examples/s]\u001B[A\n",
      "Generating train examples...:  14%|█▍        | 8477/60000 [00:05<00:28, 1839.14 examples/s]\u001B[A\n",
      "Generating train examples...:  17%|█▋        | 10425/60000 [00:06<00:26, 1875.94 examples/s]\u001B[A\n",
      "Generating train examples...:  21%|██        | 12374/60000 [00:07<00:25, 1899.55 examples/s]\u001B[A\n",
      "Generating train examples...:  24%|██▍       | 14320/60000 [00:08<00:23, 1914.17 examples/s]\u001B[A\n",
      "Generating train examples...:  27%|██▋       | 16268/60000 [00:09<00:22, 1924.73 examples/s]\u001B[A\n",
      "Generating train examples...:  30%|███       | 18214/60000 [00:10<00:21, 1931.02 examples/s]\u001B[A\n",
      "Generating train examples...:  34%|███▎      | 20160/60000 [00:11<00:20, 1935.56 examples/s]\u001B[A\n",
      "Generating train examples...:  37%|███▋      | 22109/60000 [00:12<00:19, 1939.57 examples/s]\u001B[A\n",
      "Generating train examples...:  40%|████      | 24058/60000 [00:13<00:18, 1942.13 examples/s]\u001B[A\n",
      "Generating train examples...:  43%|████▎     | 26005/60000 [00:14<00:17, 1943.50 examples/s]\u001B[A\n",
      "Generating train examples...:  47%|████▋     | 27952/60000 [00:15<00:16, 1944.28 examples/s]\u001B[A\n",
      "Generating train examples...:  50%|████▉     | 29898/60000 [00:16<00:15, 1944.77 examples/s]\u001B[A\n",
      "Generating train examples...:  53%|█████▎    | 31851/60000 [00:17<00:14, 1947.06 examples/s]\u001B[A\n",
      "Generating train examples...:  56%|█████▋    | 33799/60000 [00:18<00:13, 1946.99 examples/s]\u001B[A\n",
      "Generating train examples...:  60%|█████▉    | 35746/60000 [00:19<00:12, 1946.59 examples/s]\u001B[A\n",
      "Generating train examples...:  63%|██████▎   | 37693/60000 [00:20<00:11, 1946.43 examples/s]\u001B[A\n",
      "Generating train examples...:  66%|██████▌   | 39642/60000 [00:21<00:10, 1947.18 examples/s]\u001B[A\n",
      "Generating train examples...:  69%|██████▉   | 41590/60000 [00:22<00:09, 1945.30 examples/s]\u001B[A\n",
      "Generating train examples...:  73%|███████▎  | 43540/60000 [00:23<00:08, 1946.44 examples/s]\u001B[A\n",
      "Generating train examples...:  76%|███████▌  | 45490/60000 [00:24<00:07, 1947.46 examples/s]\u001B[A\n",
      "Generating train examples...:  79%|███████▉  | 47443/60000 [00:25<00:06, 1948.83 examples/s]\u001B[A\n",
      "Generating train examples...:  82%|████████▏ | 49393/60000 [00:26<00:05, 1948.98 examples/s]\u001B[A\n",
      "Generating train examples...:  86%|████████▌ | 51347/60000 [00:27<00:04, 1950.28 examples/s]\u001B[A\n",
      "Generating train examples...:  89%|████████▉ | 53298/60000 [00:28<00:03, 1949.86 examples/s]\u001B[A\n",
      "Generating train examples...:  92%|█████████▏| 55250/60000 [00:29<00:02, 1950.40 examples/s]\u001B[A\n",
      "Generating train examples...:  95%|█████████▌| 57203/60000 [00:30<00:01, 1951.13 examples/s]\u001B[A\n",
      "Generating train examples...:  99%|█████████▊| 59158/60000 [00:31<00:00, 1952.25 examples/s]\u001B[A\n",
      "                                                                                            \u001B[A\n",
      "Shuffling /root/tensorflow_datasets/fashion_mnist/3.0.1.incomplete69QK5H/fashion_mnist-train.tfrecord*...:   0%|          | 0/60000 [00:00<?, ? examples/s]\u001B[A\n",
      "Shuffling /root/tensorflow_datasets/fashion_mnist/3.0.1.incomplete69QK5H/fashion_mnist-train.tfrecord*...:  27%|██▋       | 16115/60000 [00:00<00:00, 161140.93 examples/s]\u001B[A\n",
      "Shuffling /root/tensorflow_datasets/fashion_mnist/3.0.1.incomplete69QK5H/fashion_mnist-train.tfrecord*...:  68%|██████▊   | 40977/60000 [00:00<00:00, 212590.08 examples/s]\u001B[A\n",
      "Generating splits...:  50%|█████     | 1/2 [00:31<00:31, 31.78s/ splits]                                                                                                   \u001B[A\n",
      "Generating test examples...:   0%|          | 0/10000 [00:00<?, ? examples/s]\u001B[A\n",
      "Generating test examples...:  19%|█▉        | 1916/10000 [00:01<00:04, 1915.47 examples/s]\u001B[A\n",
      "Generating test examples...:  39%|███▊      | 3867/10000 [00:02<00:03, 1936.00 examples/s]\u001B[A\n",
      "Generating test examples...:  58%|█████▊    | 5819/10000 [00:03<00:02, 1942.99 examples/s]\u001B[A\n",
      "Generating test examples...:  78%|███████▊  | 7774/10000 [00:04<00:01, 1947.40 examples/s]\u001B[A\n",
      "Generating test examples...:  97%|█████████▋| 9727/10000 [00:05<00:00, 1949.38 examples/s]\u001B[A\n",
      "                                                                                          \u001B[A\n",
      "Shuffling /root/tensorflow_datasets/fashion_mnist/3.0.1.incomplete69QK5H/fashion_mnist-test.tfrecord*...:   0%|          | 0/10000 [00:00<?, ? examples/s]\u001B[A\n",
      "/usr/local/lib/python3.10/dist-packages/jax/_src/xla_bridge.py:1216: UserWarning: jax.host_count has been renamed to jax.process_count. This alias will eventually be removed; please update your code.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1mDataset fashion_mnist downloaded and prepared to /root/tensorflow_datasets/fashion_mnist/3.0.1. Subsequent calls will reuse this data.\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "executionInfo": {
     "elapsed": 470,
     "status": "ok",
     "timestamp": 1607381157985,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "AfGtZHo4YYf6",
    "ExecuteTime": {
     "end_time": "2025-04-09T13:43:44.900864Z",
     "start_time": "2025-04-09T13:43:44.893865Z"
    }
   },
   "source": [
    "train_data_pipeline = preprocessing.Serial(\n",
    "    preprocessing.Shuffle(),\n",
    "    preprocessing.Batch(8),\n",
    ")\n",
    "\n",
    "train_batches_stream = train_data_pipeline(train_stream)\n",
    "\n",
    "eval_data_pipeline = preprocessing.Batch(8)\n",
    "eval_batches_stream = eval_data_pipeline(eval_stream)"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "executionInfo": {
     "elapsed": 907,
     "status": "ok",
     "timestamp": 1607381158899,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "T75v8i91ZKcp",
    "outputId": "5711f41d-2bf6-498d-fe44-247e16fadb07",
    "ExecuteTime": {
     "end_time": "2025-04-09T13:43:51.265070Z",
     "start_time": "2025-04-09T13:43:50.745966Z"
    }
   },
   "source": [
    "example_batch = next(train_batches_stream)\n",
    "print(f'batch shape (image, label) = {[x.shape for x in example_batch]}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch shape (image, label) = [(8, 28, 28, 1), (8,)]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "executionInfo": {
     "elapsed": 430,
     "status": "ok",
     "timestamp": 1607381159334,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "SbRlJX9_ZRLj",
    "ExecuteTime": {
     "end_time": "2025-04-09T13:44:45.974276Z",
     "start_time": "2025-04-09T13:44:32.104634Z"
    }
   },
   "source": [
    "from trax import layers as tl\n",
    "\n",
    "\n",
    "def get_model(n_output_classes=10):\n",
    "    model = tl.Serial(\n",
    "        tl.ToFloat(),\n",
    "\n",
    "        tl.Conv(32, (3, 3), (1, 1), 'SAME'),\n",
    "        tl.LayerNorm(),\n",
    "        tl.Relu(),\n",
    "        tl.MaxPool(),\n",
    "\n",
    "        tl.Conv(64, (3, 3), (1, 1), 'SAME'),\n",
    "        tl.LayerNorm(),\n",
    "        tl.Relu(),\n",
    "        tl.MaxPool(),\n",
    "\n",
    "        tl.Flatten(),\n",
    "        tl.Dense(n_output_classes),\n",
    "    )\n",
    "    return model"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "executionInfo": {
     "elapsed": 944,
     "status": "ok",
     "timestamp": 1607381160283,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "zv6LSQZdaV6z",
    "ExecuteTime": {
     "end_time": "2025-04-09T13:46:37.595219Z",
     "start_time": "2025-04-09T13:46:37.415939Z"
    }
   },
   "source": [
    "from trax.learning.supervised import training\n",
    "from trax import optimizers as optimizers\n",
    "\n",
    "train_task = training.TrainTask(\n",
    "    labeled_data=train_batches_stream,\n",
    "    loss_layer=tl.CategoryCrossEntropy(),\n",
    "    optimizer=optimizers.Adam(0.01),\n",
    "    n_steps_per_checkpoint=100,\n",
    ")\n",
    "\n",
    "eval_task = training.EvalTask(\n",
    "    labeled_data=eval_batches_stream,\n",
    "    metrics=[tl.CategoryCrossEntropy(), tl.CategoryAccuracy()],\n",
    "    n_eval_batches=20,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "executionInfo": {
     "elapsed": 14526,
     "status": "ok",
     "timestamp": 1607381174829,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "Rcz3ngZCa_9i",
    "outputId": "3ece3594-8835-416d-d968-205e804f4bcc",
    "ExecuteTime": {
     "end_time": "2025-04-09T14:00:09.494718Z",
     "start_time": "2025-04-09T13:59:30.753499Z"
    }
   },
   "source": [
    "model = get_model()\n",
    "\n",
    "training_loop = training.Loop(model,\n",
    "                              train_task,\n",
    "                              eval_tasks=[eval_task],\n",
    "                              output_dir='./cnn_model')\n",
    "\n",
    "training_loop.run(1000)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step      1: Total number of trainable weights: 451658\n",
      "Step      1: Ran 1 train steps in 1.08 secs\n",
      "Step      1: train CategoryCrossEntropy |  2.88087583\n",
      "Step      1: eval  CategoryCrossEntropy |  178.71961899\n",
      "Step      1: eval      CategoryAccuracy |  0.17500000\n",
      "\n",
      "Step    100: Ran 99 train steps in 4.02 secs\n",
      "Step    100: train CategoryCrossEntropy |  28.34364128\n",
      "Step    100: eval  CategoryCrossEntropy |  6.03327532\n",
      "Step    100: eval      CategoryAccuracy |  0.58125000\n",
      "\n",
      "Step    200: Ran 100 train steps in 3.41 secs\n",
      "Step    200: train CategoryCrossEntropy |  1.72970641\n",
      "Step    200: eval  CategoryCrossEntropy |  0.85664938\n",
      "Step    200: eval      CategoryAccuracy |  0.68125000\n",
      "\n",
      "Step    300: Ran 100 train steps in 3.42 secs\n",
      "Step    300: train CategoryCrossEntropy |  0.65041381\n",
      "Step    300: eval  CategoryCrossEntropy |  0.82384256\n",
      "Step    300: eval      CategoryAccuracy |  0.75000000\n",
      "\n",
      "Step    400: Ran 100 train steps in 3.40 secs\n",
      "Step    400: train CategoryCrossEntropy |  0.56752920\n",
      "Step    400: eval  CategoryCrossEntropy |  0.66170398\n",
      "Step    400: eval      CategoryAccuracy |  0.75000000\n",
      "\n",
      "Step    500: Ran 100 train steps in 3.42 secs\n",
      "Step    500: train CategoryCrossEntropy |  0.54705244\n",
      "Step    500: eval  CategoryCrossEntropy |  0.57693993\n",
      "Step    500: eval      CategoryAccuracy |  0.76250000\n",
      "\n",
      "Step    600: Ran 100 train steps in 3.42 secs\n",
      "Step    600: train CategoryCrossEntropy |  0.49513826\n",
      "Step    600: eval  CategoryCrossEntropy |  0.55107352\n",
      "Step    600: eval      CategoryAccuracy |  0.78125000\n",
      "\n",
      "Step    700: Ran 100 train steps in 3.38 secs\n",
      "Step    700: train CategoryCrossEntropy |  0.51234412\n",
      "Step    700: eval  CategoryCrossEntropy |  0.29429557\n",
      "Step    700: eval      CategoryAccuracy |  0.90000000\n",
      "\n",
      "Step    800: Ran 100 train steps in 3.44 secs\n",
      "Step    800: train CategoryCrossEntropy |  0.53655255\n",
      "Step    800: eval  CategoryCrossEntropy |  0.54376852\n",
      "Step    800: eval      CategoryAccuracy |  0.81250000\n",
      "\n",
      "Step    900: Ran 100 train steps in 3.44 secs\n",
      "Step    900: train CategoryCrossEntropy |  0.47296596\n",
      "Step    900: eval  CategoryCrossEntropy |  0.52999992\n",
      "Step    900: eval      CategoryAccuracy |  0.82500000\n",
      "\n",
      "Step   1000: Ran 100 train steps in 3.47 secs\n",
      "Step   1000: train CategoryCrossEntropy |  0.48157749\n",
      "Step   1000: eval  CategoryCrossEntropy |  0.52642396\n",
      "Step   1000: eval      CategoryAccuracy |  0.77500000\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T13:59:23.825215Z",
     "start_time": "2025-04-09T13:59:23.817029Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import shutil\n",
    "\n",
    "shutil.rmtree(training_loop.output_dir)"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 530,
     "status": "ok",
     "timestamp": 1607381175378,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "AMhqFx6HbOs_"
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Fashion MNIST with Trax.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
