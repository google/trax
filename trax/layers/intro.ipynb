{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7yuytuIllsv1"
      },
      "source": [
        "# A Conceptual, Practical Introduction to Trax Layers\n",
        "\n",
        "This notebook introduces the core concepts and programming components of the Trax library through a series of code samples and explanations. The topics covered in following sections are:\n",
        "\n",
        "  1. **Layers**: the basic building blocks and how to combine them into networks\n",
        "  1. **Data Streams**: how individual layers manage inputs and outputs\n",
        "  1. **Data Stack**: how the Trax runtime manages data streams for the layers\n",
        "  1. **Defining New Layer Classes**: how to define and test your own layer classes\n",
        "  1. **Models**: how to train, evaluate, and run predictions with Trax models\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BIl27504La0G"
      },
      "source": [
        "## General Setup\n",
        "Execute the following few cells (once) before running any of the code samples in this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "oILRLCWN_16u"
      },
      "outputs": [],
      "source": [
        "# Copyright 2018 Google LLC.\n",
        "\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "import numpy as onp  # np used below for trax.backend.numpy\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "cellView": "both",
        "colab": {
          "height": 50
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 435,
          "status": "ok",
          "timestamp": 1572449244389,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 420
        },
        "id": "vlGjGoGMTt-D",
        "outputId": "238e04ef-4ca8-40a3-d5a3-f0c3e4025c9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/bin/sh: pip: command not found\n",
            "/bin/sh: pip: command not found\n"
          ]
        }
      ],
      "source": [
        "# Import Trax\n",
        "\n",
        "! pip install -q -U trax\n",
        "! pip install -q tensorflow\n",
        "\n",
        "from trax import backend\n",
        "from trax import layers as tl\n",
        "from trax import shapes\n",
        "from trax.backend import numpy as np  # For use in defining new layer types.\n",
        "from trax.shapes import ShapeDtype\n",
        "from trax.shapes import signature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "bYWNWL9MJHv9"
      },
      "outputs": [],
      "source": [
        "# Settings and utilities for handling inputs, outputs, and object properties.\n",
        "\n",
        "onp.set_printoptions(precision=3)  # Reduce visual noise from extra digits.\n",
        "\n",
        "def show_layer_properties(layer_obj, layer_name):\n",
        "  template = ('{}.n_in:  {}\\n'\n",
        "              '{}.n_out: {}\\n'\n",
        "              '{}.sublayers: {}\\n'\n",
        "              '{}.weights:    {}\\n')\n",
        "  print(template.format(layer_name, layer_obj.n_in,\n",
        "                        layer_name, layer_obj.n_out,\n",
        "                        layer_name, layer_obj.sublayers,\n",
        "                        layer_name, layer_obj.weights))\n",
        "\n",
        "def floats_range(start, end):\n",
        "  return onp.arange(start, end).astype(onp.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-LQ89rFFsEdk"
      },
      "source": [
        "# 1. Layers\n",
        "\n",
        "The Layer class represents Trax's concept of a layer, as summarized in the start of the class's docstring:\n",
        "```\n",
        "class Layer(object):\n",
        "  \"\"\"Base class for composable layers in a deep learning network.\n",
        "\n",
        "  Layers are the basic building blocks for deep learning models. A Trax layer\n",
        "  computes a function from zero or more inputs to zero or more outputs,\n",
        "  optionally using trainable parameters (common) and non-parameter state (not\n",
        "  common). Authors of new layer subclasses typically override at most two\n",
        "  methods of the base `Layer` class:\n",
        "\n",
        "    forward(inputs, params=(), state=(), **kwargs):\n",
        "      Computes this layer's output as part of a forward pass through the model.\n",
        "\n",
        "    new_params_and_state(self, input_signature, rng):\n",
        "      Returns a (params, state) pair suitable for initializing this layer.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LyLVtdxorDPO"
      },
      "source": [
        "## A layer computes a function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ntZ4_eNQldzL"
      },
      "source": [
        "A layer computes a function from zero or more inputs to zero or more outputs. The inputs and outputs are NumPy arrays or JAX objects behaving as NumPy arrays.\n",
        "\n",
        "The simplest layers, those with no parameters, state or sublayers, can be used without initialization. You can think of them (and test them) like simple mathematical functions. For ease of testing and interactive exploration, layer\n",
        "objects implement the `__call__ ` method, so you can call them directly on input data:\n",
        "```\n",
        "y = my_layer(x)\n",
        "```\n",
        "\n",
        "Layers are also objects, so you can inspect their properties. For example:\n",
        "```\n",
        "print('Number of inputs expected by this layer: {}'.format(my_layer.n_in))\n",
        "```\n",
        "\n",
        "### Example 1. tl.Relu $[n_{in} = 1, n_{out} = 1]$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 216
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 625,
          "status": "ok",
          "timestamp": 1572449245352,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 420
        },
        "id": "V09viOSEQvQe",
        "outputId": "180b1306-1d2b-4bec-cf0c-da0d2c764325"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x:\n",
            "[[-7. -6. -5. -4. -3.]\n",
            " [-2. -1.  0.  1.  2.]\n",
            " [ 3.  4.  5.  6.  7.]]\n",
            "\n",
            "relu(x):\n",
            "[[0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 2.]\n",
            " [3. 4. 5. 6. 7.]]\n",
            "\n",
            "number of inputs expected by this layer: 1\n",
            "number of outputs promised by this layer: 1\n"
          ]
        }
      ],
      "source": [
        "x = floats_range(-7, 8).reshape(3, -1)\n",
        "\n",
        "# Create a layer object (a Relu instance) and apply the layer to data x.\n",
        "relu = tl.Relu()\n",
        "y = relu(x)\n",
        "\n",
        "# Show input, output, and two layer properties.\n",
        "template = ('x:\\n{}\\n\\n'\n",
        "            'relu(x):\\n{}\\n\\n'\n",
        "            'number of inputs expected by this layer: {}\\n'\n",
        "            'number of outputs promised by this layer: {}')\n",
        "print(template.format(x, y, relu.n_in, relu.n_out))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7sYxIT8crFVE"
      },
      "source": [
        "### Example 2. tl.Concatenate $[n_{in} = 2, n_{out} = 1]$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 433
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 419,
          "status": "ok",
          "timestamp": 1572449245792,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 420
        },
        "id": "LMPPNWXLoOZI",
        "outputId": "e7d0c066-79f1-43ac-ab07-01137d992ffd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x1:\n",
            "[[-7. -6. -5. -4. -3.]\n",
            " [-2. -1.  0.  1.  2.]\n",
            " [ 3.  4.  5.  6.  7.]]\n",
            "\n",
            "x2:\n",
            "[[-70. -60. -50. -40. -30.]\n",
            " [-20. -10.   0.  10.  20.]\n",
            " [ 30.  40.  50.  60.  70.]]\n",
            "\n",
            "concat0([x1, x2]):\n",
            "[[ -7.  -6.  -5.  -4.  -3.]\n",
            " [ -2.  -1.   0.   1.   2.]\n",
            " [  3.   4.   5.   6.   7.]\n",
            " [-70. -60. -50. -40. -30.]\n",
            " [-20. -10.   0.  10.  20.]\n",
            " [ 30.  40.  50.  60.  70.]]\n",
            "\n",
            "concat1([x1, x2]):\n",
            "[[ -7.  -6.  -5.  -4.  -3. -70. -60. -50. -40. -30.]\n",
            " [ -2.  -1.   0.   1.   2. -20. -10.   0.  10.  20.]\n",
            " [  3.   4.   5.   6.   7.  30.  40.  50.  60.  70.]]\n",
            "\n",
            "concat0: Concatenate{in=2,out=1}\n",
            "concat1: Concatenate{in=2,out=1}\n"
          ]
        }
      ],
      "source": [
        "x1 = floats_range(-7, 8).reshape(3, -1)\n",
        "x2 = 10 * x1\n",
        "\n",
        "concat0 = tl.Concatenate(axis=0)\n",
        "concat1 = tl.Concatenate(axis=1)\n",
        "\n",
        "y0 = concat0([x1, x2])\n",
        "y1 = concat1([x1, x2])\n",
        "\n",
        "template = ('x1:\\n{}\\n\\n'\n",
        "            'x2:\\n{}\\n\\n'\n",
        "            'concat0([x1, x2]):\\n{}\\n\\n'\n",
        "            'concat1([x1, x2]):\\n{}\\n')\n",
        "print(template.format(x1, x2, y0, y1))\n",
        "\n",
        "# Print abbreviated object representations (useful for debugging).\n",
        "print('concat0: {}'.format(concat0))\n",
        "print('concat1: {}'.format(concat1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1oZv3R8bRMvF"
      },
      "source": [
        "## Layers are trainable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3d64M7wLryji"
      },
      "source": [
        "Most layer types are trainable: they include parameters that modify the computation of outputs from inputs, and they use back-progagated gradients to update those parameters.\n",
        "\n",
        "Before use, trainable layers must have their parameters initialized, typically using a PRNG (pseudo-random number generator) key for random number generation. Trax's model trainers take care of this behind the scenes, but if you are using a layer in insolation, you have to do the initialization yourself. For this, use the `initialize_once` method:\n",
        "\n",
        "```\n",
        "  def initialize_once(self, input_signature):\n",
        "    \"\"\"Initializes this layer and its sublayers recursively.\n",
        "\n",
        "    This method is designed to initialize each layer instance once, even if the\n",
        "    same layer instance occurs in multiple places in the network. This enables\n",
        "    weight sharing to be implemented as layer sharing.\n",
        "\n",
        "    ...\n",
        "```\n",
        "\n",
        "### Example 3. tl.LayerNorm $[n_{in} = 1, n_{out} = 1]$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 216
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 1184,
          "status": "ok",
          "timestamp": 1572449246994,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 420
        },
        "id": "Ie7iyX91qAx2",
        "outputId": "94bdcc86-0afe-4333-de58-ac8a5f752d3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x:\n",
            "[[-7. -6. -5. -4. -3.]\n",
            " [-2. -1.  0.  1.  2.]\n",
            " [ 3.  4.  5.  6.  7.]]\n",
            "\n",
            "layer_norm(x):\n",
            "[[-1.414 -0.707  0.     0.707  1.414]\n",
            " [-1.414 -0.707  0.     0.707  1.414]\n",
            " [-1.414 -0.707  0.     0.707  1.414]]\n",
            "\n",
            "layer_norm.weights:\n",
            "(_FilledConstant([1., 1., 1., 1., 1.], dtype=float32), _FilledConstant([0., 0., 0., 0., 0.], dtype=float32))\n"
          ]
        }
      ],
      "source": [
        "x = floats_range(-7, 8).reshape(3, -1)\n",
        "\n",
        "layer_norm = tl.LayerNorm()\n",
        "layer_norm.initialize_once(signature(x))\n",
        "y = layer_norm(x)\n",
        "\n",
        "template = ('x:\\n{}\\n\\n'\n",
        "            'layer_norm(x):\\n{}\\n')\n",
        "print(template.format(x, y))\n",
        "print('layer_norm.weights:\\n{}'.format(layer_norm.weights))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZWZUXEJAofH-"
      },
      "source": [
        "## Layers combine into layers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "d47gVdGV1vWw"
      },
      "source": [
        "The Trax library authors encourage users, where possible, to build new layers as combinations of existing layers. The library provides a small set of _combinator_ layers for this: layer objects that make a list of layers behave as a single layer (a unit able to compute outputs from inputs, update parameters from gradients, and combine with yet more layers).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vC1ymG2j0iyp"
      },
      "source": [
        "## Combine with Serial(...)\n",
        "\n",
        "The most common way to combine layers is serially, using the `Serial` class:\n",
        "```\n",
        "class Serial(base.Layer):\n",
        "  \"\"\"Combinator that applies layers serially (by function composition).\n",
        "\n",
        "  A Serial combinator uses stack semantics to manage data for its sublayers.\n",
        "  Each sublayer sees only the inputs it needs and returns only the outputs it\n",
        "  has generated. The sublayers interact via the data stack. For instance, a\n",
        "  sublayer k, following sublayer j, gets called with the data stack in the\n",
        "  state left after layer j has applied. The Serial combinator then:\n",
        "\n",
        "    - takes n_in items off the top of the stack (n_in = k.n_in) and calls\n",
        "      layer k, passing those items as arguments; and\n",
        "\n",
        "    - takes layer k's n_out return values (n_out = k.n_out) and pushes\n",
        "      them onto the data stack.\n",
        "\n",
        "  ...\n",
        "```\n",
        "If one layer has the same number of outputs as the next layer has inputs (which is quite common), the successive layers behave like function composition:\n",
        "\n",
        "```\n",
        "#  h(.) = g(f(.))\n",
        "layer_h = Serial(\n",
        "    layer_f,\n",
        "    layer_g,\n",
        ")\n",
        "```\n",
        "\n",
        "### Example 4. y = layer_norm(relu(x)) $[n_{in} = 1, n_{out} = 1]$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 166
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 475,
          "status": "ok",
          "timestamp": 1572449247495,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 420
        },
        "id": "dW5fpusjvjmh",
        "outputId": "ae261223-06ba-4d98-9c6d-c673c3b5a0d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x:\n",
            "[[-7. -6. -5. -4. -3.]\n",
            " [-2. -1.  0.  1.  2.]\n",
            " [ 3.  4.  5.  6.  7.]]\n",
            "\n",
            "layer_block(x):\n",
            "[[ 0.     0.     0.     0.     0.   ]\n",
            " [-0.75  -0.75  -0.75   0.5    1.75 ]\n",
            " [-1.414 -0.707  0.     0.707  1.414]]\n"
          ]
        }
      ],
      "source": [
        "x = floats_range(-7, 8).reshape(3, -1)\n",
        "\n",
        "layer_block = tl.Serial(\n",
        "    tl.Relu(),\n",
        "    tl.LayerNorm(),\n",
        ")\n",
        "layer_block.initialize_once(signature(x))\n",
        "y = layer_block(x)\n",
        "\n",
        "template = ('x:\\n{}\\n\\n'\n",
        "            'layer_block(x):\\n{}')\n",
        "print(template.format(x, y,))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bRtmN6ckQO1q"
      },
      "source": [
        "And we can inspect the block as a whole, as if it were just another layer:\n",
        "\n",
        "### Example 4'. Inspecting a Serial layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 100
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 310,
          "status": "ok",
          "timestamp": 1572449247826,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 420
        },
        "id": "D6BpYddZQ1eu",
        "outputId": "840624e1-b28e-4807-ebc9-cc8914c12c4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "layer_block:\n",
            "Serial{in=1,out=1,sublayers=[Relu{in=1,out=1}, LayerNorm{in=1,out=1}]}\n",
            "\n",
            "layer_block.weights:\n",
            "[(), (_FilledConstant([1., 1., 1., 1., 1.], dtype=float32), _FilledConstant([0., 0., 0., 0., 0.], dtype=float32))]\n"
          ]
        }
      ],
      "source": [
        "print('layer_block:\\n{}\\n'.format(layer_block))\n",
        "\n",
        "print('layer_block.weights:\\n{}'.format(layer_block.weights))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PqVNdoONcTp0"
      },
      "source": [
        "## Combine with Parallel(...)\n",
        "\n",
        "The `Parallel` combinator arranges layers into separate computational channels, each with its own inputs/outputs and gradient flows:\n",
        "```\n",
        "class Parallel(base.Layer):\n",
        "  \"\"\"Combinator that applies a list of layers in parallel to its inputs.\n",
        "\n",
        "  Layers in the list apply to successive spans of inputs, where the spans are\n",
        "  determined how many inputs each layer takes. The resulting output is the\n",
        "  (flattened) concatenation of the resepective layer outputs.\n",
        "\n",
        "  For example, suppose one has three layers:\n",
        "\n",
        "    - F: 1 input, 1 output\n",
        "    - G: 3 inputs, 1 output\n",
        "    - H: 2 inputs, 2 outputs (h1, h2)\n",
        "\n",
        "  Then Parallel(F, G, H) will take 6 inputs and give 4 outputs:\n",
        "\n",
        "    - inputs: a, b, c, d, e, f\n",
        "    - outputs: F(a), G(b, c, d), h1, h2\n",
        "```\n",
        "\n",
        "Separate (parallel) computation channels make sense when each channel can do its work (computing outputs from inputs) independent of the inputs and outputs of the others.\n",
        "\n",
        "As a simplistic example, consider writing a converter from three-digit octal (base 8) numerals to their corresponding values. For instance, to do conversions such as\n",
        "```\n",
        "123 (octal) = 1 * 8^2 + 2 * 8^1 + 3 * 8^0 =  83 (decimal)\n",
        "345 (octal) = 3 * 8^2 + 4 * 8^1 + 5 * 8^0 = 229 (decimal)\n",
        "567 (octal) = 5 * 8^2 + 6 * 8^1 + 7 * 8^0 = 375 (decimal)\n",
        "701 (octal) = 7 * 8^2 + 0 * 8^1 + 1 * 8^0 = 449 (decimal)\n",
        "```\n",
        "the digits can first be converted independently, according to their place value (multiply by 64, multiply by 8, or multiply by 1). The following code runs the 64's-place digits ([1, 3, 5, 7]) through one layer, the 8's-place digits ([2, 4, 6, 0]) through a different layer, and the 1's-place digits ([3, 5, 7, 1]) through yet a different layer. These three layers are combined in a Parallel layer.\n",
        "\n",
        "### Example 5. Processing octal digits in parallel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 200
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 486,
          "status": "ok",
          "timestamp": 1572449248328,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 420
        },
        "id": "uQMqq3h_b2jQ",
        "outputId": "8a973ddc-7852-4e0a-b2f8-674b0ccfb8dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "inputs:\n",
            "(array([1, 3, 5, 7]), array([2, 4, 6, 0]), array([3, 5, 7, 1]))\n",
            "\n",
            "octal_place_values(inputs):\n",
            "(array([ 64., 192., 320., 448.]), array([16., 32., 48.,  0.]), array([3., 5., 7., 1.]))\n",
            "\n",
            "octal_place_values.n_in:  3\n",
            "octal_place_values.n_out: 3\n",
            "octal_place_values.sublayers: [MulConstant{in=1,out=1}, MulConstant{in=1,out=1}, MulConstant{in=1,out=1}]\n",
            "octal_place_values.weights:    ((), (), ())\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Set up three input channels, for digits with different place values.\n",
        "place_64_digits = onp.array([1, 3, 5, 7])\n",
        "place_8_digits = onp.array([2, 4, 6, 0])\n",
        "place_1_digits = onp.array([3, 5, 7, 1])\n",
        "inputs = (place_64_digits, place_8_digits, place_1_digits)\n",
        "input_shapes = [[3]] * 3\n",
        "input_dtypes = [onp.int32] * 3\n",
        "input_signature = (ShapeDtype((3, ), onp.int32),) * 3\n",
        "\n",
        "# Create three simple layers, each for computing a specific base 8 place value.\n",
        "# Then create a combined layer to convert the respective digits in parallel.\n",
        "# Initialize the combined layer and apply it.\n",
        "sixty_fours = tl.MulConstant(constant=64.0)  # 8^2: '100' in base 8 digits\n",
        "eights = tl.MulConstant(constant=8.0)        # 8^1:  '10' in base 8 digits\n",
        "ones = tl.MulConstant(constant=1.0)          # 8^0:   '1' in base 8 digits\n",
        "octal_place_values = tl.Parallel(sixty_fours, eights, ones)\n",
        "octal_place_values.initialize_once(input_signature)\n",
        "outputs = octal_place_values(inputs)\n",
        "\n",
        "# Show inputs, outputs, and properties.\n",
        "template = ('inputs:\\n{}\\n\\n'\n",
        "            'octal_place_values(inputs):\\n{}\\n')\n",
        "print(template.format(inputs, outputs))\n",
        "show_layer_properties(octal_place_values, 'octal_place_values')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "q_xcWide3e5f"
      },
      "source": [
        "To complete the example, the three output streams for the different place values are combined by successive pairwise additions.\n",
        "\n",
        "### Example 5'. Combining outputs from the parallel digit processors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 270
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 320,
          "status": "ok",
          "timestamp": 1572449248672,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 420
        },
        "id": "ZDCkrvUp3u0-",
        "outputId": "6df6ba97-c6ba-42a5-d5c9-97f007013472"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "inputs:\n",
            "(array([1, 3, 5, 7]), array([2, 4, 6, 0]), array([3, 5, 7, 1]))\n",
            "\n",
            "octal_place_values(inputs):\n",
            "(array([ 64., 192., 320., 448.]), array([16., 32., 48.,  0.]), array([3., 5., 7., 1.]))\n",
            "\n",
            "evaluate_octal(inputs):\n",
            "[ 83. 229. 375. 449.]\n",
            "\n",
            "evaluate_octal.n_in:  3\n",
            "evaluate_octal.n_out: 1\n",
            "evaluate_octal.sublayers: [Parallel{in=3,out=3,sublayers=[MulConstant{in=1,out=1}, MulConstant{in=1,out=1}, MulConstant{in=1,out=1}]}, Add{in=2,out=1}, Add{in=2,out=1}]\n",
            "evaluate_octal.weights:    [((), (), ()), (), ()]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "evaluate_octal = tl.Serial(\n",
        "    tl.Parallel(sixty_fours, eights, ones),\n",
        "    tl.Add(),  # Add the 64's-place values and the 8's-place values.\n",
        "    tl.Add(),  # Add the 1's-place values to the sums from the previous Add.\n",
        ")\n",
        "evaluate_octal.initialize_once(input_signature)\n",
        "y = evaluate_octal(inputs)\n",
        "\n",
        "template = ('inputs:\\n{}\\n\\n'\n",
        "            'octal_place_values(inputs):\\n{}\\n\\n'\n",
        "            'evaluate_octal(inputs):\\n{}\\n')\n",
        "print(template.format(inputs, outputs, y))\n",
        "show_layer_properties(evaluate_octal, 'evaluate_octal')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RObDHVC3fkzR"
      },
      "source": [
        "# 2. Data Streams"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zr2ZZ1vO8T8V"
      },
      "source": [
        "The trax runtime supports the concept of multiple data streams, which gives individual layers flexibility to:\n",
        "  - process a single data stream ($n_{out} = n_{in} = 1$),\n",
        "  - process multiple parallel data streams ($n_{out} = n_{in} = 2, 3, ... $),\n",
        "  - split data streams ($n_{out} \u003e n_{in}$), or\n",
        "  - merge data streams ($n_{out} \u003c n_{in}$).\n",
        "\n",
        "The Trax library handles residual connections, for example, as three layers that in turn do a split, a parallel process, and a merge:\n",
        "```\n",
        "def Residual(*layers, **kwargs):\n",
        "  \"\"\"Adds a residual connection in parallel to a series of layers.\"\"\"\n",
        "  shortcut = kwargs.get('shortcut')  # default None signals no-op\n",
        "  return [\n",
        "      Dup(),  # pylint: disable=no-value-for-parameter\n",
        "      Parallel(shortcut, layers),\n",
        "      Add(),  # pylint: disable=no-value-for-parameter\n",
        "  ]\n",
        "```\n",
        "\n",
        "In more detail, the logic is:\n",
        "  - `Dup()`: make two identical copies of the single incoming data stream\n",
        "  - `Parallel(shortcut, layers)`: pass one copy via the shortcut (typically a no-op) and process the other copy via the given layers, applied in series\n",
        "  - `Add()`: combine the two streams back into one by adding elementwise\n",
        "\n",
        "### Example 6. Residual connections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "duw8a53g_oLG"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QQVo6vhPgO9x"
      },
      "source": [
        "# 3. Data Stack"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "65ite-671cTT"
      },
      "source": [
        "# 4. Defining New Layer Classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hHSaD9H6hDTf"
      },
      "source": [
        "## Simpler layers, with the `@layer` decorator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cqM6WJwNhoHI"
      },
      "source": [
        "## Full subclass definitions, where necessary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "llAH3cdE1UeU"
      },
      "source": [
        "# 5. Models"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "last_runtime": {
        "build_target": "//learning/deepmind/dm_python:dm_notebook",
        "kind": "private"
      },
      "name": "A Conceptual, Practical Introduction to Trax Layers",
      "provenance": [
        {
          "file_id": "1sF8QbqJ19ZU6oy5z4GUTt4lgUCjqO6kt",
          "timestamp": 1569980697572
        },
        {
          "file_id": "1EH76AWQ_pvT4i8ZXfkv-SCV4MrmllEl5",
          "timestamp": 1563927451951
        }
      ]
    },
    "kernelspec": {
      "display_name": "Python 2",
      "name": "python2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
